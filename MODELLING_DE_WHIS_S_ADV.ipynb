{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcription with advance data preprocessing and augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep for device config(device type = arm mac sillicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mps config\n",
    "import torch\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.backends.mps.is_available() else torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# included in the training\n",
    "model.config.forced_decoder_ids = None\n",
    "model.config.suppress_tokens = []\n",
    "# to use gradient checkpointing\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Into train, test, and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n",
       "        num_rows: 488\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n",
       "        num_rows: 62\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n",
       "        num_rows: 61\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import  DatasetDict, load_dataset\n",
    "\n",
    "ds = DatasetDict()\n",
    "\n",
    "ds = load_dataset(\"PolyAI/minds14\", \"de-DE\")\n",
    "\n",
    "train_testvalid = ds['train'].train_test_split(test_size=0.2)\n",
    "# Split the 10% test + valid in half test, half valid\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5)\n",
    "# gather everyone if you want to have a single DatasetDict\n",
    "ds = DatasetDict({\n",
    "    'train': train_testvalid['train'],\n",
    "    'test': test_valid['test'],\n",
    "    'valid': test_valid['train']})\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assigning new dataset for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjust frequency and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Audio, DatasetDict, concatenate_datasets\n",
    "\n",
    "AUDIO_COLUMN_NAME = \"audio\"\n",
    "TEXT_COLUMN_NAME = \"transcription\"\n",
    "\n",
    "\n",
    "def normalize_dataset(ds, audio_column_name=None, text_column_name=None):\n",
    "    if audio_column_name is not None and audio_column_name != AUDIO_COLUMN_NAME:\n",
    "        ds = ds.rename_column(audio_column_name, AUDIO_COLUMN_NAME)\n",
    "    if text_column_name is not None and text_column_name != TEXT_COLUMN_NAME:\n",
    "        ds = ds.rename_column(text_column_name, TEXT_COLUMN_NAME)\n",
    "    # resample to the same sampling rate\n",
    "    ds = ds.cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "    # normalise columns to [\"audio\", \"sentence\"]\n",
    "    ds = ds.remove_columns(set(ds.features.keys()) - set([AUDIO_COLUMN_NAME, TEXT_COLUMN_NAME]))\n",
    "    return ds\n",
    "\n",
    "raw_datasets = DatasetDict()\n",
    "\n",
    "ds['train'] = normalize_dataset(ds['train'])\n",
    "ds['test'] = normalize_dataset(ds['test'])\n",
    "ds['valid'] = normalize_dataset(ds['valid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmentation in data train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiomentations import (\n",
    "    AddBackgroundNoise,\n",
    "    AddGaussianNoise,\n",
    "    Compose,\n",
    "    Gain,\n",
    "    OneOf,\n",
    "    PitchShift,\n",
    "    PolarityInversion,\n",
    "    TimeStretch,\n",
    ")\n",
    "\n",
    "BASE_PATH = \"./MInDS-14/audio\"\n",
    "\n",
    "# define augmentation\n",
    "augmentation = Compose(\n",
    "    [\n",
    "        TimeStretch(min_rate=0.9, max_rate=1.1, p=0.2, leave_length_unchanged=False),\n",
    "        Gain(min_gain_in_db=-6, max_gain_in_db=6, p=0.1),\n",
    "        PitchShift(min_semitones=-4, max_semitones=4, p=0.2),\n",
    "        OneOf(\n",
    "            [\n",
    "                AddBackgroundNoise(sounds_path=BASE_PATH, min_snr_in_db=1.0, max_snr_in_db=5.0, noise_transform=PolarityInversion(), p=1.0),\n",
    "                AddGaussianNoise(min_amplitude=0.005, max_amplitude=0.015, p=1.0),\n",
    "            ],\n",
    "            p=0.2,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def augment_dataset(batch):\n",
    "    # load and (possibly) resample audio data to 16kHz\n",
    "    sample = batch[AUDIO_COLUMN_NAME]\n",
    "\n",
    "    # apply augmentation\n",
    "    augmented_waveform = augmentation(sample[\"array\"], sample_rate=sample[\"sampling_rate\"])\n",
    "    batch[AUDIO_COLUMN_NAME][\"array\"] = augmented_waveform\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the length 1st!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['audio', 'transcription'],\n",
       "    num_rows: 488\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agument and Add into existing(now we have 976 instead 488 train data!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "augment train dataset (num_proc=4): 100%|██████████| 488/488 [00:12<00:00, 37.84 examples/s] \n"
     ]
    }
   ],
   "source": [
    "# augment training data\n",
    "augmented_ds = ds[\"train\"].map(\n",
    "    augment_dataset, num_proc=4, desc=\"augment train dataset\"\n",
    ")\n",
    "\n",
    "# combine\n",
    "ds[\"train\"] = concatenate_datasets([ds[\"train\"], augmented_ds])\n",
    "ds[\"train\"] = ds[\"train\"].shuffle(seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['audio', 'transcription'],\n",
       "    num_rows: 976\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.whisper.english_normalizer import BasicTextNormalizer ## Basic Text normalizer is multilingual\n",
    " \n",
    "normalizer = BasicTextNormalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor, WhisperFeatureExtractor, WhisperTokenizer\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"german\", task=\"transcribe\")\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"german\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_normalize_text = True\n",
    "\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    # load\n",
    "    audio = batch[AUDIO_COLUMN_NAME]\n",
    "    # compute log-Mel input features from input audio array\n",
    "    batch[\"input_features\"] = processor.feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "    # compute input length of audio sample in seconds\n",
    "    batch[\"input_length\"] = len(audio[\"array\"]) / audio[\"sampling_rate\"]\n",
    "\n",
    "    # process targets\n",
    "    input_str = normalizer(batch[TEXT_COLUMN_NAME]).strip() if do_normalize_text else batch[TEXT_COLUMN_NAME]\n",
    "    # encode target text to label ids\n",
    "    batch[\"labels\"] = processor.tokenizer(input_str).input_ids\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preprocess dataset (num_proc=4): 100%|██████████| 976/976 [00:02<00:00, 387.13 examples/s]\n",
      "preprocess dataset (num_proc=4): 100%|██████████| 62/62 [00:00<00:00, 82.25 examples/s]\n",
      "preprocess dataset (num_proc=4): 100%|██████████| 61/61 [00:00<00:00, 82.99 examples/s]\n"
     ]
    }
   ],
   "source": [
    "vectorized_datasets = ds.map(\n",
    "    prepare_dataset,\n",
    "    num_proc=4,\n",
    "    remove_columns=next(iter(ds.values())).column_names,\n",
    "    desc=\"preprocess dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter dataset by input length for get balance distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 30\n",
    "min_input_length = 0\n",
    "\n",
    "\n",
    "def is_audio_in_length_range(length):\n",
    "    return length > min_input_length and length < max_input_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=4): 100%|██████████| 976/976 [00:00<00:00, 10916.49 examples/s]\n",
      "Filter (num_proc=4): 100%|██████████| 62/62 [00:00<00:00, 713.05 examples/s]\n",
      "Filter (num_proc=4): 100%|██████████| 61/61 [00:00<00:00, 570.28 examples/s]\n"
     ]
    }
   ],
   "source": [
    "vectorized_datasets = vectorized_datasets.filter(\n",
    "    is_audio_in_length_range, num_proc=4, input_columns=[\"input_length\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_label_length = model.config.max_length\n",
    "\n",
    "\n",
    "def is_labels_in_length_range(labels):\n",
    "    return len(labels) < max_label_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=4): 100%|██████████| 972/972 [00:00<00:00, 10352.52 examples/s]\n",
      "Filter (num_proc=4): 100%|██████████| 60/60 [00:00<00:00, 690.09 examples/s]\n",
      "Filter (num_proc=4): 100%|██████████| 59/59 [00:00<00:00, 675.46 examples/s]\n"
     ]
    }
   ],
   "source": [
    "vectorized_datasets = vectorized_datasets.filter(\n",
    "    is_labels_in_length_range, num_proc=4, input_columns=[\"labels\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Data Colator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        # convert to tensors\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad label ids to the max length in the batch\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Metrics (WER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate with the 'normalized' WER\n",
    "do_normalize_eval = True\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    if do_normalize_eval:\n",
    "        pred_str = [normalizer(pred) for pred in pred_str]\n",
    "        # perhaps already normalised\n",
    "        label_str = [normalizer(label) for label in label_str]\n",
    "        # filtering step to only evaluate the samples that correspond to non-zero references\n",
    "        pred_str = [pred_str[i] for i in range(len(pred_str)) if len(label_str[i]) > 0]\n",
    "        label_str = [label_str[i] for i in range(len(label_str)) if len(label_str[i]) > 0]\n",
    "\n",
    "    wer = metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training args & Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./whisper-small-ger-lr6.25-adv\",\n",
    "    per_device_train_batch_size=8, \n",
    "    per_device_eval_batch_size=8, \n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_steps=4,\n",
    "    max_steps=122,\n",
    "    learning_rate=6.25e-6, \n",
    "    weight_decay=0.01, \n",
    "    gradient_checkpointing=True, \n",
    "    predict_with_generate=True, \n",
    "    generation_max_length=225, \n",
    "    logging_steps=8, \n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=8,\n",
    "    save_strategy=\"steps\", \n",
    "    save_steps=8,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=vectorized_datasets[\"train\"],\n",
    "    eval_dataset=vectorized_datasets[\"valid\"],\n",
    "    tokenizer=processor,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 8/122 [03:15<48:13, 25.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.983, 'grad_norm': 16.955373764038086, 'learning_rate': 6.038135593220339e-06, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "                                               \n",
      "  7%|▋         | 8/122 [04:22<48:13, 25.38s/it]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.211230754852295, 'eval_wer': 0.17956349206349206, 'eval_runtime': 67.7924, 'eval_samples_per_second': 0.87, 'eval_steps_per_second': 0.118, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 16/122 [07:41<45:14, 25.61s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9228, 'grad_norm': 15.038456916809082, 'learning_rate': 5.614406779661018e-06, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 13%|█▎        | 16/122 [09:59<45:14, 25.61s/it]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5825867652893066, 'eval_wer': 1.0952380952380953, 'eval_runtime': 137.5801, 'eval_samples_per_second': 0.429, 'eval_steps_per_second': 0.058, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 24/122 [13:19<44:24, 27.19s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3936, 'grad_norm': 11.334648132324219, 'learning_rate': 5.190677966101695e-06, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 20%|█▉        | 24/122 [15:41<44:24, 27.19s/it]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0462669134140015, 'eval_wer': 1.1845238095238095, 'eval_runtime': 142.1265, 'eval_samples_per_second': 0.415, 'eval_steps_per_second': 0.056, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 32/122 [18:50<40:16, 26.85s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9704, 'grad_norm': 9.35204029083252, 'learning_rate': 4.766949152542373e-06, 'epoch': 1.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 26%|██▌       | 32/122 [22:03<40:16, 26.85s/it]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9536905288696289, 'eval_wer': 2.3660714285714284, 'eval_runtime': 193.6582, 'eval_samples_per_second': 0.305, 'eval_steps_per_second': 0.041, 'epoch': 1.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 40/122 [25:17<38:54, 28.47s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8859, 'grad_norm': 9.82310676574707, 'learning_rate': 4.343220338983051e-06, 'epoch': 1.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 33%|███▎      | 40/122 [28:21<38:54, 28.47s/it]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9046236276626587, 'eval_wer': 2.453373015873016, 'eval_runtime': 183.436, 'eval_samples_per_second': 0.322, 'eval_steps_per_second': 0.044, 'epoch': 1.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 48/122 [31:34<35:08, 28.49s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7572, 'grad_norm': 8.358237266540527, 'learning_rate': 3.919491525423729e-06, 'epoch': 1.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 39%|███▉      | 48/122 [34:37<35:08, 28.49s/it]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.86468905210495, 'eval_wer': 2.427579365079365, 'eval_runtime': 183.2126, 'eval_samples_per_second': 0.322, 'eval_steps_per_second': 0.044, 'epoch': 1.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 56/122 [37:50<31:18, 28.46s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7469, 'grad_norm': 10.324573516845703, 'learning_rate': 3.495762711864407e-06, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 46%|████▌     | 56/122 [41:05<31:18, 28.46s/it]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8293108940124512, 'eval_wer': 2.7281746031746033, 'eval_runtime': 195.1305, 'eval_samples_per_second': 0.302, 'eval_steps_per_second': 0.041, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 64/122 [44:16<27:40, 28.63s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6778, 'grad_norm': 7.780063629150391, 'learning_rate': 3.072033898305085e-06, 'epoch': 2.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 52%|█████▏    | 64/122 [47:31<27:40, 28.63s/it]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8081901669502258, 'eval_wer': 2.818452380952381, 'eval_runtime': 195.1293, 'eval_samples_per_second': 0.302, 'eval_steps_per_second': 0.041, 'epoch': 2.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 72/122 [50:43<23:50, 28.61s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5932, 'grad_norm': 8.67540454864502, 'learning_rate': 2.648305084745763e-06, 'epoch': 2.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 59%|█████▉    | 72/122 [53:58<23:50, 28.61s/it]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7917385101318359, 'eval_wer': 2.8680555555555554, 'eval_runtime': 195.1961, 'eval_samples_per_second': 0.302, 'eval_steps_per_second': 0.041, 'epoch': 2.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 80/122 [57:09<19:55, 28.47s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5879, 'grad_norm': 8.530070304870605, 'learning_rate': 2.2245762711864407e-06, 'epoch': 2.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 66%|██████▌   | 80/122 [1:00:24<19:55, 28.47s/it]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.775465726852417, 'eval_wer': 2.7668650793650795, 'eval_runtime': 195.4123, 'eval_samples_per_second': 0.302, 'eval_steps_per_second': 0.041, 'epoch': 2.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 88/122 [1:03:34<16:08, 28.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5968, 'grad_norm': 9.402825355529785, 'learning_rate': 1.8008474576271187e-06, 'epoch': 2.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 72%|███████▏  | 88/122 [1:06:50<16:08, 28.49s/it]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.762309193611145, 'eval_wer': 2.640873015873016, 'eval_runtime': 195.7048, 'eval_samples_per_second': 0.301, 'eval_steps_per_second': 0.041, 'epoch': 2.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 96/122 [1:09:58<12:10, 28.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5491, 'grad_norm': 9.611059188842773, 'learning_rate': 1.3771186440677967e-06, 'epoch': 3.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 79%|███████▊  | 96/122 [1:13:13<12:10, 28.10s/it]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7546915411949158, 'eval_wer': 2.507936507936508, 'eval_runtime': 195.1232, 'eval_samples_per_second': 0.302, 'eval_steps_per_second': 0.041, 'epoch': 3.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 104/122 [1:16:25<08:34, 28.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4959, 'grad_norm': 7.619028091430664, 'learning_rate': 9.533898305084747e-07, 'epoch': 3.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 85%|████████▌ | 104/122 [1:19:40<08:34, 28.60s/it]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7489808201789856, 'eval_wer': 2.419642857142857, 'eval_runtime': 194.9033, 'eval_samples_per_second': 0.303, 'eval_steps_per_second': 0.041, 'epoch': 3.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 112/122 [1:22:51<04:43, 28.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4853, 'grad_norm': 7.708927631378174, 'learning_rate': 5.296610169491525e-07, 'epoch': 3.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 92%|█████████▏| 112/122 [1:26:05<04:43, 28.34s/it]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.743336021900177, 'eval_wer': 2.4057539682539684, 'eval_runtime': 194.2398, 'eval_samples_per_second': 0.304, 'eval_steps_per_second': 0.041, 'epoch': 3.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 120/122 [1:29:19<00:57, 28.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5301, 'grad_norm': 8.639152526855469, 'learning_rate': 1.0593220338983051e-07, 'epoch': 3.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 98%|█████████▊| 120/122 [1:32:34<00:57, 28.86s/it]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7405820488929749, 'eval_wer': 2.3978174603174605, 'eval_runtime': 195.1298, 'eval_samples_per_second': 0.302, 'eval_steps_per_second': 0.041, 'epoch': 3.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122/122 [1:33:24<00:00, 67.50s/it]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n",
      "There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n",
      "100%|██████████| 122/122 [1:33:29<00:00, 45.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 5609.8744, 'train_samples_per_second': 0.696, 'train_steps_per_second': 0.022, 'train_loss': 0.9373875670745725, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=122, training_loss=0.9373875670745725, metrics={'train_runtime': 5609.8744, 'train_samples_per_second': 0.696, 'train_steps_per_second': 0.022, 'total_flos': 1.12202003644416e+18, 'train_loss': 0.9373875670745725, 'epoch': 4.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model for inference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(training_args.output_dir)\n",
    "processor.save_pretrained(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>grad_norm</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_wer</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>train_runtime</th>\n",
       "      <th>train_samples_per_second</th>\n",
       "      <th>train_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.9830</td>\n",
       "      <td>16.955374</td>\n",
       "      <td>6.038136e-06</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>8</td>\n",
       "      <td>2.211231</td>\n",
       "      <td>0.179563</td>\n",
       "      <td>67.7924</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.9228</td>\n",
       "      <td>15.038457</td>\n",
       "      <td>5.614407e-06</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>16</td>\n",
       "      <td>1.582587</td>\n",
       "      <td>1.095238</td>\n",
       "      <td>137.5801</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.3936</td>\n",
       "      <td>11.334648</td>\n",
       "      <td>5.190678e-06</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>24</td>\n",
       "      <td>1.046267</td>\n",
       "      <td>1.184524</td>\n",
       "      <td>142.1265</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9704</td>\n",
       "      <td>9.352040</td>\n",
       "      <td>4.766949e-06</td>\n",
       "      <td>1.049180</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.049180</td>\n",
       "      <td>32</td>\n",
       "      <td>0.953691</td>\n",
       "      <td>2.366071</td>\n",
       "      <td>193.6582</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8859</td>\n",
       "      <td>9.823107</td>\n",
       "      <td>4.343220e-06</td>\n",
       "      <td>1.311475</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.311475</td>\n",
       "      <td>40</td>\n",
       "      <td>0.904624</td>\n",
       "      <td>2.453373</td>\n",
       "      <td>183.4360</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.7572</td>\n",
       "      <td>8.358237</td>\n",
       "      <td>3.919492e-06</td>\n",
       "      <td>1.573770</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.573770</td>\n",
       "      <td>48</td>\n",
       "      <td>0.864689</td>\n",
       "      <td>2.427579</td>\n",
       "      <td>183.2126</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.7469</td>\n",
       "      <td>10.324574</td>\n",
       "      <td>3.495763e-06</td>\n",
       "      <td>1.836066</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.836066</td>\n",
       "      <td>56</td>\n",
       "      <td>0.829311</td>\n",
       "      <td>2.728175</td>\n",
       "      <td>195.1305</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.6778</td>\n",
       "      <td>7.780064</td>\n",
       "      <td>3.072034e-06</td>\n",
       "      <td>2.098361</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.098361</td>\n",
       "      <td>64</td>\n",
       "      <td>0.808190</td>\n",
       "      <td>2.818452</td>\n",
       "      <td>195.1293</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.5932</td>\n",
       "      <td>8.675405</td>\n",
       "      <td>2.648305e-06</td>\n",
       "      <td>2.360656</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.360656</td>\n",
       "      <td>72</td>\n",
       "      <td>0.791739</td>\n",
       "      <td>2.868056</td>\n",
       "      <td>195.1961</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.5879</td>\n",
       "      <td>8.530070</td>\n",
       "      <td>2.224576e-06</td>\n",
       "      <td>2.622951</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.622951</td>\n",
       "      <td>80</td>\n",
       "      <td>0.775466</td>\n",
       "      <td>2.766865</td>\n",
       "      <td>195.4123</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.5968</td>\n",
       "      <td>9.402825</td>\n",
       "      <td>1.800847e-06</td>\n",
       "      <td>2.885246</td>\n",
       "      <td>88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.885246</td>\n",
       "      <td>88</td>\n",
       "      <td>0.762309</td>\n",
       "      <td>2.640873</td>\n",
       "      <td>195.7048</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.5491</td>\n",
       "      <td>9.611059</td>\n",
       "      <td>1.377119e-06</td>\n",
       "      <td>3.147541</td>\n",
       "      <td>96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.147541</td>\n",
       "      <td>96</td>\n",
       "      <td>0.754692</td>\n",
       "      <td>2.507937</td>\n",
       "      <td>195.1232</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.4959</td>\n",
       "      <td>7.619028</td>\n",
       "      <td>9.533898e-07</td>\n",
       "      <td>3.409836</td>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.409836</td>\n",
       "      <td>104</td>\n",
       "      <td>0.748981</td>\n",
       "      <td>2.419643</td>\n",
       "      <td>194.9033</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.4853</td>\n",
       "      <td>7.708928</td>\n",
       "      <td>5.296610e-07</td>\n",
       "      <td>3.672131</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.672131</td>\n",
       "      <td>112</td>\n",
       "      <td>0.743336</td>\n",
       "      <td>2.405754</td>\n",
       "      <td>194.2398</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.5301</td>\n",
       "      <td>8.639153</td>\n",
       "      <td>1.059322e-07</td>\n",
       "      <td>3.934426</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.934426</td>\n",
       "      <td>120</td>\n",
       "      <td>0.740582</td>\n",
       "      <td>2.397817</td>\n",
       "      <td>195.1298</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5609.8744</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.022</td>\n",
       "      <td>1.122020e+18</td>\n",
       "      <td>0.937388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      loss  grad_norm  learning_rate     epoch  step  eval_loss  eval_wer  \\\n",
       "0   2.9830  16.955374   6.038136e-06  0.262295     8        NaN       NaN   \n",
       "1      NaN        NaN            NaN  0.262295     8   2.211231  0.179563   \n",
       "2   1.9228  15.038457   5.614407e-06  0.524590    16        NaN       NaN   \n",
       "3      NaN        NaN            NaN  0.524590    16   1.582587  1.095238   \n",
       "4   1.3936  11.334648   5.190678e-06  0.786885    24        NaN       NaN   \n",
       "5      NaN        NaN            NaN  0.786885    24   1.046267  1.184524   \n",
       "6   0.9704   9.352040   4.766949e-06  1.049180    32        NaN       NaN   \n",
       "7      NaN        NaN            NaN  1.049180    32   0.953691  2.366071   \n",
       "8   0.8859   9.823107   4.343220e-06  1.311475    40        NaN       NaN   \n",
       "9      NaN        NaN            NaN  1.311475    40   0.904624  2.453373   \n",
       "10  0.7572   8.358237   3.919492e-06  1.573770    48        NaN       NaN   \n",
       "11     NaN        NaN            NaN  1.573770    48   0.864689  2.427579   \n",
       "12  0.7469  10.324574   3.495763e-06  1.836066    56        NaN       NaN   \n",
       "13     NaN        NaN            NaN  1.836066    56   0.829311  2.728175   \n",
       "14  0.6778   7.780064   3.072034e-06  2.098361    64        NaN       NaN   \n",
       "15     NaN        NaN            NaN  2.098361    64   0.808190  2.818452   \n",
       "16  0.5932   8.675405   2.648305e-06  2.360656    72        NaN       NaN   \n",
       "17     NaN        NaN            NaN  2.360656    72   0.791739  2.868056   \n",
       "18  0.5879   8.530070   2.224576e-06  2.622951    80        NaN       NaN   \n",
       "19     NaN        NaN            NaN  2.622951    80   0.775466  2.766865   \n",
       "20  0.5968   9.402825   1.800847e-06  2.885246    88        NaN       NaN   \n",
       "21     NaN        NaN            NaN  2.885246    88   0.762309  2.640873   \n",
       "22  0.5491   9.611059   1.377119e-06  3.147541    96        NaN       NaN   \n",
       "23     NaN        NaN            NaN  3.147541    96   0.754692  2.507937   \n",
       "24  0.4959   7.619028   9.533898e-07  3.409836   104        NaN       NaN   \n",
       "25     NaN        NaN            NaN  3.409836   104   0.748981  2.419643   \n",
       "26  0.4853   7.708928   5.296610e-07  3.672131   112        NaN       NaN   \n",
       "27     NaN        NaN            NaN  3.672131   112   0.743336  2.405754   \n",
       "28  0.5301   8.639153   1.059322e-07  3.934426   120        NaN       NaN   \n",
       "29     NaN        NaN            NaN  3.934426   120   0.740582  2.397817   \n",
       "30     NaN        NaN            NaN  4.000000   122        NaN       NaN   \n",
       "\n",
       "    eval_runtime  eval_samples_per_second  eval_steps_per_second  \\\n",
       "0            NaN                      NaN                    NaN   \n",
       "1        67.7924                    0.870                  0.118   \n",
       "2            NaN                      NaN                    NaN   \n",
       "3       137.5801                    0.429                  0.058   \n",
       "4            NaN                      NaN                    NaN   \n",
       "5       142.1265                    0.415                  0.056   \n",
       "6            NaN                      NaN                    NaN   \n",
       "7       193.6582                    0.305                  0.041   \n",
       "8            NaN                      NaN                    NaN   \n",
       "9       183.4360                    0.322                  0.044   \n",
       "10           NaN                      NaN                    NaN   \n",
       "11      183.2126                    0.322                  0.044   \n",
       "12           NaN                      NaN                    NaN   \n",
       "13      195.1305                    0.302                  0.041   \n",
       "14           NaN                      NaN                    NaN   \n",
       "15      195.1293                    0.302                  0.041   \n",
       "16           NaN                      NaN                    NaN   \n",
       "17      195.1961                    0.302                  0.041   \n",
       "18           NaN                      NaN                    NaN   \n",
       "19      195.4123                    0.302                  0.041   \n",
       "20           NaN                      NaN                    NaN   \n",
       "21      195.7048                    0.301                  0.041   \n",
       "22           NaN                      NaN                    NaN   \n",
       "23      195.1232                    0.302                  0.041   \n",
       "24           NaN                      NaN                    NaN   \n",
       "25      194.9033                    0.303                  0.041   \n",
       "26           NaN                      NaN                    NaN   \n",
       "27      194.2398                    0.304                  0.041   \n",
       "28           NaN                      NaN                    NaN   \n",
       "29      195.1298                    0.302                  0.041   \n",
       "30           NaN                      NaN                    NaN   \n",
       "\n",
       "    train_runtime  train_samples_per_second  train_steps_per_second  \\\n",
       "0             NaN                       NaN                     NaN   \n",
       "1             NaN                       NaN                     NaN   \n",
       "2             NaN                       NaN                     NaN   \n",
       "3             NaN                       NaN                     NaN   \n",
       "4             NaN                       NaN                     NaN   \n",
       "5             NaN                       NaN                     NaN   \n",
       "6             NaN                       NaN                     NaN   \n",
       "7             NaN                       NaN                     NaN   \n",
       "8             NaN                       NaN                     NaN   \n",
       "9             NaN                       NaN                     NaN   \n",
       "10            NaN                       NaN                     NaN   \n",
       "11            NaN                       NaN                     NaN   \n",
       "12            NaN                       NaN                     NaN   \n",
       "13            NaN                       NaN                     NaN   \n",
       "14            NaN                       NaN                     NaN   \n",
       "15            NaN                       NaN                     NaN   \n",
       "16            NaN                       NaN                     NaN   \n",
       "17            NaN                       NaN                     NaN   \n",
       "18            NaN                       NaN                     NaN   \n",
       "19            NaN                       NaN                     NaN   \n",
       "20            NaN                       NaN                     NaN   \n",
       "21            NaN                       NaN                     NaN   \n",
       "22            NaN                       NaN                     NaN   \n",
       "23            NaN                       NaN                     NaN   \n",
       "24            NaN                       NaN                     NaN   \n",
       "25            NaN                       NaN                     NaN   \n",
       "26            NaN                       NaN                     NaN   \n",
       "27            NaN                       NaN                     NaN   \n",
       "28            NaN                       NaN                     NaN   \n",
       "29            NaN                       NaN                     NaN   \n",
       "30      5609.8744                     0.696                   0.022   \n",
       "\n",
       "      total_flos  train_loss  \n",
       "0            NaN         NaN  \n",
       "1            NaN         NaN  \n",
       "2            NaN         NaN  \n",
       "3            NaN         NaN  \n",
       "4            NaN         NaN  \n",
       "5            NaN         NaN  \n",
       "6            NaN         NaN  \n",
       "7            NaN         NaN  \n",
       "8            NaN         NaN  \n",
       "9            NaN         NaN  \n",
       "10           NaN         NaN  \n",
       "11           NaN         NaN  \n",
       "12           NaN         NaN  \n",
       "13           NaN         NaN  \n",
       "14           NaN         NaN  \n",
       "15           NaN         NaN  \n",
       "16           NaN         NaN  \n",
       "17           NaN         NaN  \n",
       "18           NaN         NaN  \n",
       "19           NaN         NaN  \n",
       "20           NaN         NaN  \n",
       "21           NaN         NaN  \n",
       "22           NaN         NaN  \n",
       "23           NaN         NaN  \n",
       "24           NaN         NaN  \n",
       "25           NaN         NaN  \n",
       "26           NaN         NaN  \n",
       "27           NaN         NaN  \n",
       "28           NaN         NaN  \n",
       "29           NaN         NaN  \n",
       "30  1.122020e+18    0.937388  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "trainer_history = pd.DataFrame(trainer.state.log_history)\n",
    "trainer_history.groupby('step').first().reset_index()\n",
    "trainer_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Lowest Wer scores actualy at the early phase of training and continue rose up until step 80 and start declining! WER: 0.17%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAGuCAYAAABBQrUvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAABRa0lEQVR4nO3de1hU5d7/8c+AyEEBRePgGQ+lSJaHLNBCPKGVO60sTfNU7jLN03462JMHdJdpud1ZplntrNRSa2vZ3lqkkpoHPOETamaF2TaQkgQEwQnW7w9/zHYCdAZhDQzv13XNdbXWutfMd/B7lX2473tZDMMwBAAAAAAAAJjIw9UFAAAAAAAAoOYhlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAHAjs2bNksViKde9y5cvl8Vi0YkTJyq2KAAAgFIQSgEAADtr1qyRxWLRunXrSly74YYbZLFYtHXr1hLXmjVrpujoaNtxixYtZLFYSn3169fPNq44RCl+eXl5qUWLFpo4caLOnj1bKd/RFS7387j0tXz5cleX6jI7duxQ//791bhxY/n4+KhZs2YaMGCAVq1aZRuTl5enWbNmKTEx0XWFAgCAClHL1QUAAICqpXv37pIuBgSDBg2ync/OzlZKSopq1aqlr776SrGxsbZrP/30k3766ScNGTLE7r1uvPFG/eUvfynxGY0aNSpxbsmSJapbt65yc3O1efNmvfLKKzpw4IB27NhRUV/Npf7+97/r3LlztuN///vfev/997Vw4UI1bNjQdv7SYK88nn32WT399NPluvfBBx/UkCFD5O3tfVU1lMfatWt1//3368Ybb9SkSZNUv359paamatu2bXrjjTf0wAMPSLoYSsXHx0uSevToYXqdAACg4hBKAQAAO40aNVJ4eHiJMGjXrl0yDEODBw8uca34uDjQKta4cWMNHz7coc+99957beHMI488oiFDhmj16tVKSkpS165dy/t1TJebm6s6deqUOD9w4EC74/T0dL3//vsaOHCgWrRo4fT7laVWrVqqVat8f8Xz9PSUp6dnue69WrNmzVJERIR2796t2rVr213LyMhwSU0AAKBysXwPAACU0L17dx08eFDnz5+3nfvqq6/Uvn179e/fX7t371ZRUZHdNYvFom7dulVYDbfeeqsk6fvvv3do/Nq1a9W5c2f5+vqqYcOGGj58uE6dOmW7/tJLL8lisejHH38sce+0adNUu3Zt/fbbb7Zze/bsUb9+/RQYGCg/Pz/FxMToq6++sruveOnhkSNH9MADD6h+/folgjlnjBo1SnXr1tX333+v22+/Xf7+/ho2bJgkafv27Ro8eLCaNWsmb29vNW3aVFOmTLH7M7q0pktZLBZNmDBB69evV2RkpLy9vdW+fXtt2rTJblxpe0q1aNFCd955p3bs2KGuXbvKx8dHLVu21Lvvvlui/v/7v/9TTEyMfH191aRJE/31r3/V22+/7dA+Vd9//71uuummEoGUJAUHB0uSTpw4oWuuuUaSFB8fb1vyOGvWLNvYb775Rvfee6+CgoLk4+OjLl266JNPPin1e27btk2PPPKIGjRooICAAI0YMcKuByRp3759iouLU8OGDeXr66vw8HCNGTPmst8FAAA4hlAKAACU0L17d1mtVu3Zs8d27quvvlJ0dLSio6OVlZWllJQUu2tt27ZVgwYN7N7HarXq119/LfH6Y5BSmuIQo379+lccu3z5ct13333y9PTU3LlzNXbsWP3zn/9U9+7dbftS3XfffbJYLFqzZk2J+9esWaO+ffvaPmvLli267bbblJ2drZkzZ+r555/X2bNn1bNnTyUlJZW4f/DgwcrLy9Pzzz+vsWPHXrHey/n9998VFxen4OBgvfTSS7rnnnskXQzd8vLyNG7cOL3yyiuKi4vTK6+8ohEjRjj0vjt27NBjjz2mIUOGaP78+crPz9c999yjM2fOXPHe7777Tvfee6/69OmjBQsWqH79+ho1apQOHz5sG3Pq1CnFxsbq8OHDmjZtmqZMmaKVK1fq5Zdfdqi+5s2ba/PmzfrPf/5T5phrrrlGS5YskSQNGjRI7733nt577z3dfffdkqTDhw/rlltu0dGjR/X0009rwYIFqlOnjgYOHFjqHmkTJkzQ0aNHNWvWLI0YMUIrV67UwIEDZRiGpIsztPr27asTJ07o6aef1iuvvKJhw4Zp9+7dDn0nAABwBQYAAMAfHD582JBkzJkzxzAMw7BarUadOnWMd955xzAMwwgJCTEWL15sGIZhZGdnG56ensbYsWPt3qN58+aGpFJfc+fOtY2bOXOmIck4duyY8csvvxgnTpww/vGPfxi+vr7GNddcY+Tm5l621gsXLhjBwcFGZGSkcf78edv5Tz/91JBkzJgxw3YuKirK6Ny5s939SUlJhiTj3XffNQzDMIqKiow2bdoYcXFxRlFRkW1cXl6eER4ebvTp06dE7UOHDr3yD/UPXnzxRUOSkZqaajs3cuRIQ5Lx9NNPlxifl5dX4tzcuXMNi8Vi/PjjjyVqupQko3bt2sZ3331nO3fo0CFDkvHKK6/Yzr399tslair+c9y2bZvtXEZGhuHt7W385S9/sZ17/PHHDYvFYhw8eNB27syZM0ZQUFCJ9yzNW2+9ZaszNjbWmD59urF9+3ajsLDQbtwvv/xiSDJmzpxZ4j169eplXH/99UZ+fr7tXFFRkREdHW20adOmxPfs3LmzceHCBdv5+fPnG5KMjz/+2DAMw1i3bp0hydi7d+9lawcAAOXDTCkAAFBCu3bt1KBBA9teUYcOHVJubq5tE+7o6GjbUrZdu3apsLCw1GVrN998sxISEkq8hg4dWmLsddddp2uuuUYtWrTQmDFj1Lp1a23cuFF+fn6XrXXfvn3KyMjQY489Jh8fH9v5O+64Q23bttW//vUv27n7779f+/fvt1sSuHr1anl7e+uuu+6SJCUnJ+v48eN64IEHdObMGdvsrtzcXPXq1Uvbtm2zW7ooSY8++uhla3TWuHHjSpzz9fW1/XNubq5+/fVXRUdHyzAMHTx48Irv2bt3b7Vq1cp23KFDBwUEBOiHH3644r0RERG25ZTSxRlL1113nd29mzZtUlRUlG688UbbuaCgINvywysZM2aMNm3apB49emjHjh2aM2eObr31VrVp00Y7d+684v2ZmZnasmWL7rvvPuXk5Nj+3M6cOaO4uDgdP37cbjmnJP35z3+Wl5eX7XjcuHGqVauW/v3vf0uS6tWrJ0n69NNPZbVaHfoeAADAcWx0DgAASrBYLIqOjrYFMF999ZWCg4PVunVrSRdDqVdffVWSbOFUaaFUw4YN1bt3b4c+86OPPlJAQIB++eUXLVq0SKmpqXZBTFmK94i67rrrSlxr27at3absgwcP1tSpU7V69Wo988wzMgxDa9euVf/+/RUQECBJOn78uCRp5MiRZX5mVlaW3bLC8PBwh76jI2rVqqUmTZqUOH/y5EnNmDFDn3zySYl9j7Kysq74vs2aNStxrn79+iXeq7z3/vjjj4qKiioxrrhnHBEXF6e4uDjl5eVp//79Wr16tZYuXao777xT33zzjW1vqdJ89913MgxD06dP1/Tp00sdk5GRocaNG9uO27RpY3e9bt26CgsLsy0djYmJ0T333KP4+HgtXLhQPXr00MCBA/XAAw+45AmFAAC4G0IpAABQqu7du2vDhg36+uuvbftJFYuOjtYTTzyhU6dOaceOHWrUqJFatmx5VZ9322232Z6+N2DAAF1//fUaNmyY9u/fLw+Pipnc3ahRI916661as2aNnnnmGe3evVsnT57UvHnzbGOKZ0G9+OKLdrN+LlW3bl27Y0fCM0d5e3uX+L6FhYXq06ePMjMz9dRTT6lt27aqU6eOTp06pVGjRpWYuVWasp6qZ/z//ZMq697y8PPz06233qpbb71VDRs2VHx8vDZu3HjZoLD4Z/A///M/iouLK3WMMwGZdDGc/fDDD7V7925t2LBBn332mcaMGaMFCxZo9+7dJfoAAAA4h1AKAACUqnjm044dO/TVV19p8uTJtmudO3eWt7e3EhMTtWfPHt1+++0V+tl169bVzJkzNXr0aK1Zs0ZDhgwpc2zz5s0lSceOHVPPnj3trh07dsx2vdj999+vxx57TMeOHdPq1avl5+enAQMG2K4XL3ELCAhweJZXZfv666/17bff6p133rHb2DwhIcGFVdlr3ry5vvvuuxLnSzvnjC5dukiS0tLSJKnEkwWLFYeiXl5eDv+5HT9+XLGxsbbjc+fOKS0trUQ/33LLLbrlllv03HPPadWqVRo2bJg++OADPfzww05/HwAA8F/sKQUAAErVpUsX+fj4aOXKlTp16pTdTClvb2916tRJixcvVm5ubqlL967WsGHD1KRJE7tZTGXVGRwcrKVLl6qgoMB2fuPGjTp69KjuuOMOu/H33HOPPD099f7772vt2rW68847VadOHdv1zp07q1WrVnrppZd07ty5Ep/3yy+/XOU3c17xTKVLZyYZhuHwk+3MEBcXp127dik5Odl2LjMzUytXrnTo/s2bN5d6vnh/p+LlmcV7jBU/VbFYcHCwevTooddff90WYF2qtD+3ZcuW2e0VtWTJEv3+++/q37+/JOm3334rMRusePbcpb0GAADKh5lSAACgVLVr19ZNN92k7du3y9vbW507d7a7Hh0drQULFkgqfT8pSTp16pRWrFhR4nzdunU1cODAy36+l5eXJk2apCeeeEKbNm1Sv379yhw3b948jR49WjExMRo6dKhOnz6tl19+WS1atNCUKVPsxgcHBys2NlZ/+9vflJOTo/vvv9/uuoeHh9588031799f7du31+jRo9W4cWOdOnVKW7duVUBAgDZs2HDZ2ita27Zt1apVK/3P//yPTp06pYCAAH300UcO7QdllieffFIrVqxQnz599Pjjj6tOnTp688031axZM2VmZpY5w6nYXXfdpfDwcA0YMECtWrVSbm6uvvjiC23YsEE33XSTbTabr6+vIiIitHr1al177bUKCgpSZGSkIiMjtXjxYnXv3l3XX3+9xo4dq5YtW+r06dPatWuX/vOf/+jQoUN2n3nhwgX16tVL9913n44dO6bXXntN3bt315/+9CdJ0jvvvKPXXntNgwYNUqtWrZSTk6M33nhDAQEBFT47EACAmohQCgAAlKl79+7avn27bbnepbp166YFCxbI399fN9xwQ6n3Jycn68EHHyxxvnnz5lcMpaSLT0f761//qhdeeKHMUEqSRo0aJT8/P73wwgt66qmnVKdOHQ0aNEjz5s2zPUHtUvfff7+++OIL+fv7lxou9OjRQ7t27dKcOXP06quv6ty5cwoNDdXNN9+sRx555Ip1VzQvLy9t2LBBEydO1Ny5c+Xj46NBgwZpwoQJZf7szda0aVNt3bpVEydO1PPPP69rrrlG48ePV506dTRx4kS7JyOW5s0339THH3+sNWvW6Oeff5ZhGGrZsqX+93//V0899ZRq1aplN/bxxx/XlClTdOHCBc2cOVORkZGKiIjQvn37FB8fr+XLl+vMmTMKDg5Wx44dNWPGjBKf+eqrr2rlypWaMWOGrFarhg4dqkWLFtkCtJiYGCUlJemDDz7Q6dOnFRgYqK5du2rlypUVurk9AAA1lcWorB0qAQAAUONNnjxZr7/+us6dO1fmhulmW758uUaPHq29e/fa9qwCAADmY08pAAAAVIjz58/bHZ85c0bvvfeeunfvXmUCKQAAUHWwfA8AAAAVIioqSj169FC7du10+vRpvfXWW8rOztb06dNdXRoAAKiCCKUAAABQIW6//XZ9+OGHWrZsmSwWizp16qS33npLt912m6tLAwAAVZBL95RasmSJlixZohMnTkiS2rdvrxkzZtgew1uatWvXavr06Tpx4oTatGmjefPm8fQTAAAAAACAasale0o1adJEL7zwgvbv3699+/apZ8+euuuuu3T48OFSx+/cuVNDhw7VQw89pIMHD2rgwIEaOHCgUlJSTK4cAAAAAAAAV6PKPX0vKChIL774oh566KES1+6//37l5ubq008/tZ275ZZbdOONN2rp0qVmlgkAAAAAAICrUGX2lCosLNTatWuVm5urqKioUsfs2rVLU6dOtTsXFxen9evXl/m+BQUFKigosB0XFRUpMzNTDRo0kMViqZDaAQAAAAAAcJFhGMrJyVGjRo3k4VH2Ij2Xh1Jff/21oqKilJ+fr7p162rdunWKiIgodWx6erpCQkLszoWEhCg9Pb3M9587d67i4+MrtGYAAAAAAABc3k8//aQmTZqUed3lodR1112n5ORkZWVl6cMPP9TIkSP15ZdflhlMOWvatGl2s6uysrLUrFkzpaamyt/fv0I+A3CU1WrV1q1bFRsbKy8vL1eXA1QI+hruhp6GO6Kv4Y7oa7gbd+rpnJwchYeHXzF3cXkoVbt2bbVu3VqS1LlzZ+3du1cvv/yyXn/99RJjQ0NDdfr0abtzp0+fVmhoaJnv7+3tLW9v7xLng4KCFBAQcJXVA86xWq3y8/NTgwYNqv2/ZIBi9DXcDT0Nd0Rfwx3R13A37tTTxfVfadsklz59rzRFRUV2e0BdKioqSps3b7Y7l5CQUOYeVAAAAAAAAKiaXDpTatq0aerfv7+aNWumnJwcrVq1SomJifrss88kSSNGjFDjxo01d+5cSdKkSZMUExOjBQsW6I477tAHH3ygffv2admyZa78GgAAAAAAAHCSS0OpjIwMjRgxQmlpaQoMDFSHDh302WefqU+fPpKkkydP2u3SHh0drVWrVunZZ5/VM888ozZt2mj9+vWKjIx01VcAAAAAAABAObg0lHrrrbcuez0xMbHEucGDB2vw4MGVVBEAAAAAAKgpCgsLZbVaXV2GpIt7StWqVUv5+fkqLCx0dTmX5eXlJU9Pz6t+H5dvdA4AAAAAAGAmwzCUnp6us2fPuroUG8MwFBoaqp9++umKG4RXBfXq1VNoaOhV1UooBQAAAAAAapTiQCo4OFh+fn5VIgQqKirSuXPnVLduXbutjKoawzCUl5enjIwMSVJYWFi534tQCgAAAAAA1BiFhYW2QKpBgwauLsemqKhIFy5ckI+PT5UOpSTJ19dX0sW9woODg8u9lK9qf0sAAAAAAIAKVLyHlJ+fn4srqd6Kf35XsycXM6UAAABQbRUWGUpKzVRGTr6C/X3UNTxInh6uX4IBAKj6qsKSveqsIn5+hFIAAAColjalpCl+wxGlZeXbzoUF+mjmgAj1iyz//hYAAMAcLN8DAABAtbMpJU3jVhywC6QkKT0rX+NWHNCmlDQXVQYAABxFKAUAAIBqpbDIUPyGIzJKuVZ8Ln7DERUWlTYCAICKUVhkaNf3Z/Rx8int+v5Mpf93Z+nSpfL399fvv/9uO3fu3Dl5eXmpR48edmMTExNlsVj0/fffq0WLFrJYLCVeL7zwgiTpxIkTdueDgoIUExOj7du3V+r3kVi+BwAAgGomKTWzxAypSxmS0rLylZSaqahWVeepSgAA9+GKJeSxsbE6d+6c9u3bp1tuuUWStH37doWGhmrPnj3Kz8+Xj4+PJGnr1q1q1qyZWrVqJUmaPXu2xo4da/d+/v7+dsdffPGF2rdvr19//VXPPfec7rzzTn377bcKCQmplO8jMVMKAACgSjP7t7DVQUZO2YFUecYBAOAMVy0hv+666xQWFqbExETbucTERN11110KDw/X7t277c7Hxsbajv39/RUaGmr3qlOnjt37N2jQQKGhoYqMjNQzzzyj7Oxs7dmzp1K+SzFmSgEAAFRRbORdumB/nwodBwCo2QzD0HlroUNjC4sMzfzkcJlLyC2SZn1yRN1aN3ToabC+Xp5OPcUuNjZWW7du1dNPPy3p4oyoJ598UoWFhdq6dat69Oih8+fPa8+ePRozZozD73up8+fP691335Uk1a5du1zv4ShCKQAAgCqo+Lewf/xLb/FvYZcM71Rjg6mu4UEKC/RRelZ+qf9TYJEUGuijruFBZpcGAKiGzlsLFTHjswp5L0NSena+rp/1uUPjj8yOk19tx6OZ2NhYTZ48Wb///rvOnz+vgwcPKiYmRlarVUuXLpUk7dq1SwUFBXYzpZ566ik9++yzdu+1ceNG3Xrrrbbj6OhoeXh4KC8vT4ZhqHPnzurVq5fDtZUHy/cAAACqGDbyvjxPD4tmDoiQdDGAulTx8cwBEQ79hhoAgOqkR48eys3N1d69e7V9+3Zde+21uuaaaxQTE2PbVyoxMVEtW7ZUs2bNbPc98cQTSk5Otnt16dLF7r1Xr16tgwcP6qOPPlLr1q21fPlyeXl5Ver3YaYUAABAFcNG3lfWLzJMS4Z3KrG8MZTljQAAJ/l6eerI7DiHxialZmrU23uvOG756JscmrHr6+Xp0OcWa926tZo0aaKtW7fqt99+U0xMjCSpUaNGatq0qXbu3KmtW7eqZ8+edvc1bNhQrVu3vux7N23aVG3atFGbNm30+++/a9CgQUpJSZG3t7dTNTqDUAoAAKCKYSNvx/SLDFOfiFAlpWYqIydfwf4Xl+wxQwoA4AyLxeLwErpb21zj0BLyW9tcU2n/PYqNjVViYqJ+++03PfHEE7bzt912mzZu3KikpCSNGzfuqj7j3nvv1YwZM/Taa69pypQpV1tymVi+BwAAUMWwkbfjPD0simrVQHfd2FhRrRoQSJWisMjQntRM7f/Voj2pmTV22ScAVISqsIQ8NjZWO3bsUHJysm2mlCTFxMTo9ddf14ULF+z2k5KknJwcpaen272ys7PL/AyLxaKJEyfqhRdeUF5eXqV9F0IpAACAKqZ4I++y/jpr0cWn8LGRN65kU0qaus/bouH/2Kd3j3tq+D/2qfu8LZX2uHIAqAmKl5CHBtr/cig00MeUB5HExsbq/Pnzat26tUJCQmznY2JilJOTo+uuu05hYfY1zJgxQ2FhYXavJ5988rKfM3LkSFmtVr366quV8j0klu8BAABUOcW/hR234oAskt3yADbyhqN4giMAVB5XLiFv0aKFDKPkrNfmzZuXev7EiRPlej8/Pz9lZmaWu05HMFMKAACgCnL1b2FRvfEERwCofCwhv3rMlAIAAKii2Mgb5cUTHAEA1QGhFAAAcJnCIoPA5QqKfwsLOIMnOAIAqgNCKQAA4BKbUtIUv+GI3WyOsEAfzRwQwdI04CrxBEcAQHXAnlIAAMB0xRsw/3F5UfEGzDwZDLg6PMERAK6stM294biK+PkRSgEAAFOxATNQ+Yqf4CipRDDFExwB1HReXl6SpLy8PBdXUr0V//yKf57lwfI9AABgKjZgBsxR/ATHPy6TDWWZLIAaztPTU/Xq1VNGRoYkyc/PTxaL60P6oqIiXbhwQfn5+fLwqLpziAzDUF5enjIyMlSvXj15enqW+70IpQAAgKnYgBkwT/ETHHd9l6HPt+9R31tvVlTrYGZIAajxQkNDJckWTFUFhmHo/Pnz8vX1rRIh2ZXUq1fP9nMsL0IpAABgKjZgBszl6WHRzeFBOnPU0M084RIAJEkWi0VhYWEKDg6W1Wp1dTmSJKvVqm3btum22267qiVxZvDy8rqqGVLFCKUAAICpijdgTs/KL3VfKYsuLi9iA2YAAFDZPD09KyRcqQienp76/fff5ePjU+VDqYpSdRcpAgAAt8QGzAAAAJAIpQAAgAsUb8AcGmi/RC800EdLhndiA2YAAIAagOV7AADAJYo3YE5KzVRGTr6C/S8u2WOGFACzFRYZ/LsIAFyAUAoAALiMp4dFUa0auLoMADXYppQ0xW84orSs/z7xMyzQRzMHRDBrEwAqGcv3AAAAANRIm1LSNG7FAbtASpLSs/I1bsUBbUpJc1FlAFAzEEoBAAAAqHEKiwzFbzhS6lNAi8/FbziiwqLSRgAAKgKhFAAAAIAaJyk1s8QMqUsZktKy8pWUmmleUQBQwxBKAQAAAKhxMnLKDqTKMw4A4DxCKQAAAAA1TrC/T4WOAwA4j1AKAAAAQI3TNTxIYYE+spRx3aKLT+HrGh5kZlkAUKMQSgEAAACocTw9LJo5IEKSSgRTxcczB0TI06Os2AoAcLUIpQAAAADUSP0iw7RkeCeFBtov0QsN9NGS4Z3ULzLMRZUBQM1Qy9UFAAAAAICr9IsMU5+IUCWlZiojJ1/B/heX7DFDCgAqH6EUAAAAgBrN08OiqFYNXF0GANQ4LN8DAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmY6NzAAAAAECZCosMnk4IoFK4dKbU3LlzddNNN8nf31/BwcEaOHCgjh07dtl7li9fLovFYvfy8fExqWIAAAAAqDk2paSp+7wtGvrGbk36IFlD39it7vO2aFNKmqtLA+AGXBpKffnllxo/frx2796thIQEWa1W9e3bV7m5uZe9LyAgQGlpabbXjz/+aFLFAAAAAFAzbEpJ07gVB5SWlW93Pj0rX+NWHCCYAnDVXLp8b9OmTXbHy5cvV3BwsPbv36/bbrutzPssFotCQ0MruzwAAAAAqJEKiwzFbzgio5RrhiSLpPgNR9QnIpSlfADKrUptdJ6VlSVJCgoKuuy4c+fOqXnz5mratKnuuusuHT582IzyAAAAAKBGSErNLDFD6lKGpLSsfCWlZppXFAC3U2U2Oi8qKtLkyZPVrVs3RUZGljnuuuuu0z/+8Q916NBBWVlZeumllxQdHa3Dhw+rSZMmJcYXFBSooKDAdpydnS1JslqtslqtFf9FgMso7jl6D+6Evoa7oafhjuhrOCvt7OW3VLl0nNUaUMnVlI6+hrtxp5529DtYDMMobUam6caNG6eNGzdqx44dpYZLZbFarWrXrp2GDh2qOXPmlLg+a9YsxcfHlzi/atUq+fn5XVXNAFDTFRnS99kWZVulAC+pVYAhZvADAFD9Hc+y6NUjnlccNyGiUG0Cq8T/UgKoQvLy8vTAAw8oKytLAQFlB9dVIpSaMGGCPv74Y23btk3h4eFO3z948GDVqlVL77//folrpc2Uatq0qX799dfL/mCAymC1WpWQkKA+ffrIy8vL1eUAV+Wzw6f1139/o/Ts//47NjTAW8/e3lZx7UNcWBlwdfh3NdwRfQ1nFRYZ6rFgm05nF5S6r5RFUmigt7ZOvc1le0rR13A37tTT2dnZatiw4RVDKZcu3zMMQ48//rjWrVunxMTEcgVShYWF+vrrr3X77beXet3b21ve3t4lznt5eVX7P2RUX/QfqrtNKWl6/INDJf6Sejq7QI9/cEhLhndSv8gwl9QGVBT+XQ13RF/DUV6SZv2pvcatOCCLZPff/OIIauaA9vLxrm1+cX9AX8PduENPO1q/Szc6Hz9+vFasWKFVq1bJ399f6enpSk9P1/nz521jRowYoWnTptmOZ8+erc8//1w//PCDDhw4oOHDh+vHH3/Uww8/7IqvAAA1zpWexiNdfBpPYZHLJ+K6XGGRoV3fn9HHyae06/sz/EwAANVKv8gwLRneSaGBPnbnQwN9+AUUgArh0plSS5YskST16NHD7vzbb7+tUaNGSZJOnjwpD4//Zme//fabxo4dq/T0dNWvX1+dO3fWzp07FRERYVbZAFCjOfM0nqhWDcwrrIrZlJKm+A1H7H5WYYE+mjkggr/EAwCqjX6RYeoTEaqk1Exl5OQr2N9HXcODXLZkr6oqLDL4GQHl4PLle1eSmJhod7xw4UItXLiwkioCAFxJRk7ZgVR5xrmjTSlpGrfiQInZZOlZ+Rq34gC/XQYAVCueHpYa/YumK+EXUUD5uXT5HgCg+gn297nyICfGuRuWNwIAUHMU/yLqj7PIi38RtSklzUWVVT1sa4DSuHSmFACg+ukaHqSwQB+lZ+Vf5mk8F6et10QsbwQAoGa40i+iLLr4i6g+EaE1fikfs8murLDI0J7UTO3/1aIGqZmKah1cI/qGmVIAAKd4elg0c8DFffz++J/J/z6NJ6JG/Ee0NCxvBACgZnDmF1E1GbPJrmxTSpq6z9ui4f/Yp3ePe2r4P/ap+7wtNeJnQygFAHAaT+MpG8sbAQCoGfhF1JWxrcGV1fTQjuV7AFAGnqJyecVP49n1XYY+375HfW+9ucZMM74cljcCAFAz8IuoK2Nbg8tjCSihFACUinXvjvH0sOjm8CCdOWroZkI7Sf9d3jhuxQFZJLu/ZLC8EQAA98Evoq6M2WSXR2jH8j0AKKGmT6HF1WN5IwAA7o99Nq+M2WSXR2jHTCkAsMMUWlSU4uWNLAEFAMB9Ff8i6o8z7EOZYS+J2WRXQmhHKAUAdphCi4rk6WGhTwAAcHP8IqpsbGtweYR2LN8DADtMoQUAAICzin8RddeNjRXVqkGNDVlKw7YGZWMJKDOlAMAOU2gBAACAisVssrLV9CWghFIAcAmm0AIAAAAVj20NylYc2u36LkOfb9+jvrferKjWwTUitGP5HgBcgim0AAAAAMzm6WHRzeFB6tzQ0M01aBYZoRQA/AHr3gEAAACg8rF8DwBKwbp3AAAAAKhchFIAUAbWvQMAAABA5WH5HgAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMB2hFAAAAAAAAExHKAUAAAAAAADTEUoBAAAAAADAdIRSAAAAAAAAMJ1LQ6m5c+fqpptukr+/v4KDgzVw4EAdO3bsivetXbtWbdu2lY+Pj66//nr9+9//NqFaAAAAAAAAVBSXhlJffvmlxo8fr927dyshIUFWq1V9+/ZVbm5umffs3LlTQ4cO1UMPPaSDBw9q4MCBGjhwoFJSUkysHAAAAAAAAFejlis/fNOmTXbHy5cvV3BwsPbv36/bbrut1Htefvll9evXT0888YQkac6cOUpISNCrr76qpUuXVnrNAAAAAAAAuHouDaX+KCsrS5IUFBRU5phdu3Zp6tSpdufi4uK0fv36UscXFBSooKDAdpydnS1JslqtslqtV1kx4JzinqP34E7oa7gbehruiL6GO6Kv4W7cqacd/Q5VJpQqKirS5MmT1a1bN0VGRpY5Lj09XSEhIXbnQkJClJ6eXur4uXPnKj4+vsT5zz//XH5+fldXNFBOCQkJri4BqHD0NdwNPQ13RF/DHdHXcDfu0NN5eXkOjasyodT48eOVkpKiHTt2VOj7Tps2zW5mVXZ2tpo2baq+ffsqICCgQj8LuBKr1aqEhAT16dNHXl5eri4HqBD0NdwNPQ13RF/DHdHXcDfu1NPFq9SupEqEUhMmTNCnn36qbdu2qUmTJpcdGxoaqtOnT9udO336tEJDQ0sd7+3tLW9v7xLnvby8qv0fMqov+g/uiL6Gu6Gn4Y7oa7gj+hruxh162tH6nX76Xm5urqZPn67o6Gi1bt1aLVu2tHs5wzAMTZgwQevWrdOWLVsUHh5+xXuioqK0efNmu3MJCQmKiopy6rMBAAAAAADgOk7PlHr44Yf15Zdf6sEHH1RYWJgsFku5P3z8+PFatWqVPv74Y/n7+9v2hQoMDJSvr68kacSIEWrcuLHmzp0rSZo0aZJiYmK0YMEC3XHHHfrggw+0b98+LVu2rNx1AAAAAAAAwFxOh1IbN27Uv/71L3Xr1u2qP3zJkiWSpB49etidf/vttzVq1ChJ0smTJ+Xh8d8JXdHR0Vq1apWeffZZPfPMM2rTpo3Wr19/2c3RAQAAAAAAULU4HUrVr19fQUFBFfLhhmFccUxiYmKJc4MHD9bgwYMrpAYAAAAAAACYz+k9pebMmaMZM2Y4/Hg/AAAAAAAA4I+cnim1YMECff/99woJCVGLFi1K7Kh+4MCBCisOAAAAAAAA7snpUGrgwIGVUAYAAAAAAABqEqdDqZkzZ1ZGHQAAAAAAAKhBnA6liu3fv19Hjx6VJLVv314dO3assKIAAAAAAADg3pwOpTIyMjRkyBAlJiaqXr16kqSzZ88qNjZWH3zwga655pqKrhEAAAAAAABuxumn7z3++OPKycnR4cOHlZmZqczMTKWkpCg7O1sTJ06sjBoBAAAAAADgZpyeKbVp0yZ98cUXateune1cRESEFi9erL59+1ZocQAAAAAAAHBPTs+UKioqkpeXV4nzXl5eKioqqpCiAAAAAAAA4N6cDqV69uypSZMm6eeff7adO3XqlKZMmaJevXpVaHEAAAAAAABwT06HUq+++qqys7PVokULtWrVSq1atVJ4eLiys7P1yiuvVEaNAAAAAAAAcDNO7ynVtGlTHThwQF988YW++eYbSVK7du3Uu3fvCi8OAAAAAAAA7snpUEqSLBaL+vTpoz59+lR0PQAAAAAAAKgBHAqlFi1apD//+c/y8fHRokWLLjt24sSJFVIYAAAAAAAA3JdDodTChQs1bNgw+fj4aOHChWWOs1gshFIAAAAAAAC4IodCqdTU1FL/GQAAAAAAACgPp5++N3v2bOXl5ZU4f/78ec2ePbtCigIAAAAAAIB7czqUio+P17lz50qcz8vLU3x8fIUUBQAAAAAAAPfmdChlGIYsFkuJ84cOHVJQUFCFFAUAAAAAAAD35tCeUpJUv359WSwWWSwWXXvttXbBVGFhoc6dO6dHH320UooEAAAAAACAe3E4lPr73/8uwzA0ZswYxcfHKzAw0Hatdu3aatGihaKioiqlSAAAAAAAALgXh0OpkSNHSpLCw8MVHR0tLy+vSisKAAAAAAAA7s3hUKpYTEyM7Z/z8/N14cIFu+sBAQFXXxUAAAAAAADcmtMbnefl5WnChAkKDg5WnTp1VL9+fbsXAAAAAAAAcCVOh1JPPPGEtmzZoiVLlsjb21tvvvmm4uPj1ahRI7377ruVUSMAAAAAAADcjNPL9zZs2KB3331XPXr00OjRo3XrrbeqdevWat68uVauXKlhw4ZVRp0AAAAAAABwI07PlMrMzFTLli0lXdw/KjMzU5LUvXt3bdu2rWKrAwAAAAAAgFtyOpRq2bKlUlNTJUlt27bVmjVrJF2cQVWvXr0KLQ4AAAAAAADuyelQavTo0Tp06JAk6emnn9bixYvl4+OjKVOm6IknnqjwAgEAAAAAAOB+nN5TasqUKbZ/7t27t7755hvt379frVu3VocOHSq0OAAAAAAAALgnp0OpP2revLmaN29eEbUAAAAAAACghnA6lJo9e/Zlr8+YMaPcxQAAAAAAAKBmcDqUWrdund2x1WpVamqqatWqpVatWhFKAQAAAAAA4IqcDqUOHjxY4lx2drZGjRqlQYMGVUhRAAAAAAAAcG9OP32vNAEBAYqPj9f06dMr4u0AAAAAAADg5ioklJKkrKwsZWVlVdTbAQAAAAAAwI05vXxv0aJFdseGYSgtLU3vvfee+vfvX2GFAQAAAAAAwH05HUotXLjQ7tjDw0PXXHONRo4cqWnTplVYYQAAAAAAAHBfTodSqamplVEHAAAAAAAAapAK21MKAAAAAAAAcJRDM6Xuvvtuh9/wn//8Z7mLAQAAAAAAQM3gUCgVGBhY2XUAAAAAAACgBnEolHr77bcruw4AAAAAAADUIOwpBQAAAAAAANM5/fQ9Sfrwww+1Zs0anTx5UhcuXLC7duDAgQopDAAAAAAAAO7L6ZlSixYt0ujRoxUSEqKDBw+qa9euatCggX744Qf179+/MmoEAAAAAACAm3E6lHrttde0bNkyvfLKK6pdu7aefPJJJSQkaOLEicrKyqqMGgEAAAAAAOBmnA6lTp48qejoaEmSr6+vcnJyJEkPPvig3n//fafea9u2bRowYIAaNWoki8Wi9evXX3Z8YmKiLBZLiVd6erqzXwMAAAAAAAAu5HQoFRoaqszMTElSs2bNtHv3bklSamqqDMNw6r1yc3N1ww03aPHixU7dd+zYMaWlpdlewcHBTt0PAAAAAAAA13J6o/OePXvqk08+UceOHTV69GhNmTJFH374ofbt26e7777bqffq379/ufahCg4OVr169Zy+DwAAAAAAAFWD06HUsmXLVFRUJEkaP368GjRooJ07d+pPf/qTHnnkkQovsDQ33nijCgoKFBkZqVmzZqlbt25lji0oKFBBQYHtODs7W5JktVpltVorvVbgUsU9R+/BndDXcDf0NNwRfQ13RF/D3bhTTzv6HSyGs2vuKonFYtG6des0cODAMsccO3ZMiYmJ6tKliwoKCvTmm2/qvffe0549e9SpU6dS75k1a5bi4+NLnF+1apX8/PwqqnwAAAAAAABIysvL0wMPPKCsrCwFBASUOc7pUKp169YaPny4HnjgAV177bVXXaitEAdCqdLExMSoWbNmeu+990q9XtpMqaZNm+rXX3+97A8GqAxWq1UJCQnq06ePvLy8XF0OUCHoa7gbehruiL6GO6Kv4W7cqaezs7PVsGHDK4ZSTi/fGz9+vFatWqU5c+aoU6dOGj58uO6//36FhoZeVcHl1bVrV+3YsaPM697e3vL29i5x3svLq9r/IaP6ov/gjuhruBt6Gu6IvoY7oq/hbtyhpx2t3+mn702ZMkV79+7V0aNHdfvtt2vx4sVq2rSp+vbtq3fffdfpQq9WcnKywsLCTP9cAAAAAAAAlJ/ToVSxa6+9VvHx8fr222+1fft2/fLLLxo9erRT73Hu3DklJycrOTlZkpSamqrk5GSdPHlSkjRt2jSNGDHCNv7vf/+7Pv74Y3333XdKSUnR5MmTtWXLFo0fP768XwMAAAAAAAAu4PTyvUslJSVp1apVWr16tbKzszV48GCn7t+3b59iY2Ntx1OnTpUkjRw5UsuXL1daWpotoJKkCxcu6C9/+YtOnTolPz8/dejQQV988YXdewAAAAAAAKDqczqU+vbbb7Vy5Uq9//77Sk1NVc+ePTVv3jzdfffdqlu3rlPv1aNHD11un/Xly5fbHT/55JN68sknnS0ZAAAAAAAAVYzToVTbtm110003afz48RoyZIhCQkIqoy4AAAAAAAC4MadDqWPHjqlNmzaVUQsAAAAAAABqCIc3Ok9KSlJhYWGZgVRBQYHWrFlTYYUBAAAAAADAfTkcSkVFRenMmTO244CAAP3www+247Nnz2ro0KEVWx0AAAAAAADcksOh1B83JC9tg/LLbVoOAAAAAAAAFHM4lHKExWKpyLcDAAAAAACAm6rQUAoAAAAAAABwhFNP3zty5IjS09MlXVyq98033+jcuXOSpF9//bXiqwMAAAAAAIBbciqU6tWrl92+UXfeeaeki8v2DMNg+R4AAAAAAAAc4nAolZqaWpl1AAAAAAAAoAZxOJRq3rx5ZdYBAAAAAACAGoSNzgEAAAAAAGA6QikAAAAAAACYjlAKAAAAAAAApiOUAgAAAAAAgOkqLJTKz8/XSy+9VFFvBwAAAAAAADfmVCj1yy+/6NNPP9Xnn3+uwsJCSZLVatXLL7+sFi1a6IUXXqiUIgEAAAAAAOBeajk6cMeOHbrzzjuVnZ0ti8WiLl266O2339bAgQNVq1YtzZo1SyNHjqzMWgEAAAAAAOAmHJ4p9eyzz+r222/X//3f/2nq1Knau3evBg0apOeff15HjhzRo48+Kl9f38qsFQAAAAAAAG7C4VDq66+/1rPPPqvIyEjNnj1bFotF8+fP17333luZ9QEAAAAAAMANORxK/fbbb2rYsKEkydfXV35+foqMjKy0wgAAAAAAAOC+HN5TSpKOHDmi9PR0SZJhGDp27Jhyc3PtxnTo0KHiqgMAAAAAAIBbciqU6tWrlwzDsB3feeedkiSLxSLDMGSxWGxP5QMAAAAAAADK4nAolZqaWpl1AAAAAAAAoAZxOJRq3rx5ZdYBAAAAAACAGsThjc7nz5+v8+fP246/+uorFRQU2I5zcnL02GOPVWx1ACpNYZGhXd+f0cfJp7Tr+zMqLDKufBMAAAAAABXE4VBq2rRpysnJsR33799fp06dsh3n5eXp9ddfr9jqAFSKTSlp6j5vi4a+sVuTPkjW0Dd2q/u8LdqUkubq0gAAAAAANYTDodSlG5yXdgygetiUkqZxKw4oLSvf7nx6Vr7GrThAMAUAAAAAMIXDoRSA6q+wyFD8hiMqLVIuPhe/4QhL+QAAAAAAlY5QCqhBklIzS8yQupQhKS0rX0mpmeYVBQAAAACokRx++p4kvfnmm6pbt64k6ffff9fy5cvVsGFDSbLbbwpA1ZSRU3YgVZ5xAAAAAACUl8OhVLNmzfTGG2/YjkNDQ/Xee++VGAOg6gr296nQcQAAAAAAlJfDodSJEycqsQwAZugaHqSwQB+lZ+WXuq+URVJooI+6hgeZXRoAAAAAoIZxeE+p1NTUyqwDgAk8PSyaOSBC0sUA6lLFxzMHRMjT449XAQAAAACoWA6HUq1atVJ4eLjGjBmj9957T//5z38qsy4AlaRfZJiWDO+k0ED7JXqhgT5aMryT+kWGuagyAAAAAEBN4vDyvS1btigxMVGJiYl6//33deHCBbVs2VI9e/ZUbGysYmNjFRISUpm1Ak4pLDKUlJqpjJx8BftfXJLGDKCL+kWGqU9EKD8fAAAAAIDLOBxK9ejRQz169JAk5efna+fOnbaQ6p133pHValXbtm11+PDhyqoVcNimlDTFbziitKz/PkUuLNBHMwdEMBPo//P0sCiqVQNXlwEAAAAAqKEcDqUu5ePjo549e6p79+6KjY3Vxo0b9frrr+ubb76p6PoAp21KSdO4FQdKbOSdnpWvcSsOsEQNAAAAAIAqwOE9pSTpwoUL2rZtm+Lj4xUbG6t69erp0Ucf1W+//aZXX32VzdDhcoVFhuI3HCn1yXLF5+I3HFFhUWkjAAAAAACAWRyeKdWzZ0/t2bNH4eHhiomJ0SOPPKJVq1YpLIwZJ6g6klIz7Zbs/ZEhKS0rX0mpmSxdAwAAAADAhRwOpbZv366wsDD17NlTPXr0UExMjBo04H/qUbVk5JQdSJVnHAAAAAAAqBwOL987e/asli1bJj8/P82bN0+NGjXS9ddfrwkTJujDDz/UL7/8Upl1Ag4J9vep0HEAAAAAAKByOBxK1alTR/369dMLL7ygPXv26Ndff9X8+fPl5+en+fPnq0mTJoqMjKzMWoEr6hoepLBAH1nKuG7RxafwdQ0PMrMsAAAAAADwB05tdH6pOnXqKCgoSEFBQapfv75q1aqlo0ePVmRtgNM8PSyaOSBCkkoEU8XHMwdEyNOjrNgKAAAAAACYweFQqqioSElJSZo/f7769++vevXqKTo6Wq+99ppCQ0O1ePFi/fDDD5VZK+CQfpFhWjK8k0ID7ZfohQb6aMnwTuoXyeb8AAAAAAC4msMbnderV0+5ubkKDQ1VbGysFi5cqB49eqhVq1aVWR9QLv0iw9QnIlRJqZnKyMlXsP/FJXvMkAIAAAAAoGpwOJR68cUXFRsbq2uvvbYy6wEqjKeHRVGteEIkAAAAAABVkcPL9x555JEKD6S2bdumAQMGqFGjRrJYLFq/fv0V70lMTFSnTp3k7e2t1q1ba/ny5RVaEwAAAAAAACpfuTc6rwi5ubm64YYbtHjxYofGp6am6o477lBsbKySk5M1efJkPfzww/rss88quVIAAAAAAABUJIeX71WG/v37q3///g6PX7p0qcLDw7VgwQJJUrt27bRjxw4tXLhQcXFxlVUmAAAAAAAAKphLQyln7dq1S71797Y7FxcXp8mTJ5d5T0FBgQoKCmzH2dnZkiSr1Sqr1VopdQJlKe45eg/uhL6Gu6Gn4Y7oa7gj+hruxp162tHvUK1CqfT0dIWEhNidCwkJUXZ2ts6fPy9fX98S98ydO1fx8fElzn/++efy8/OrtFqBy0lISHB1CUCFo6/hbuhpuCP6Gu6Ivoa7cYeezsvLc2hctQqlymPatGmaOnWq7Tg7O1tNmzZV3759FRAQ4MLKUBNZrVYlJCSoT58+8vLycnU5QIWgr+Fu6Gm4I/oa7oi+hrtxp54uXqV2JdUqlAoNDdXp06ftzp0+fVoBAQGlzpKSJG9vb3l7e5c47+XlVe3/kFF90X9wR/Q13A09DXdEX8Md0ddwN+7Q047W79Kn7zkrKipKmzdvtjuXkJCgqKgoF1UEAAAAAACA8nBpKHXu3DklJycrOTlZkpSamqrk5GSdPHlS0sWldyNGjLCNf/TRR/XDDz/oySef1DfffKPXXntNa9as0ZQpU1xRPgAAAAAAAMrJpaHUvn371LFjR3Xs2FGSNHXqVHXs2FEzZsyQJKWlpdkCKkkKDw/Xv/71LyUkJOiGG27QggUL9OabbyouLs4l9QMAAAAAAKB8XLqnVI8ePWQYRpnXly9fXuo9Bw8erMSqAAAAAAAAUNmq1Z5SAAAAAAAAcA+EUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA01WJUGrx4sVq0aKFfHx8dPPNNyspKanMscuXL5fFYrF7+fj4mFgtAAAAAAAArpbLQ6nVq1dr6tSpmjlzpg4cOKAbbrhBcXFxysjIKPOegIAApaWl2V4//vijiRUDAAAAAADgark8lPrb3/6msWPHavTo0YqIiNDSpUvl5+enf/zjH2XeY7FYFBoaanuFhISYWDEAAAAAAACuVi1XfviFCxe0f/9+TZs2zXbOw8NDvXv31q5du8q879y5c2revLmKiorUqVMnPf/882rfvn2pYwsKClRQUGA7zs7OliRZrVZZrdYK+iaAY4p7jt6DO6Gv4W7oabgj+hruiL6Gu3Gnnnb0O1gMwzAquZYy/fzzz2rcuLF27typqKgo2/knn3xSX375pfbs2VPinl27dun48ePq0KGDsrKy9NJLL2nbtm06fPiwmjRpUmL8rFmzFB8fX+L8qlWr5OfnV7FfCAAAAAAAoIbLy8vTAw88oKysLAUEBJQ5zqUzpcojKirKLsCKjo5Wu3bt9Prrr2vOnDklxk+bNk1Tp061HWdnZ6tp06bq27fvZX8wQGWwWq1KSEhQnz595OXl5epygApBX8Pd0NNwR/Q13BF9DXfjTj1dvErtSlwaSjVs2FCenp46ffq03fnTp08rNDTUoffw8vJSx44d9d1335V63dvbW97e3qXeV93/kFF90X9wR/Q13A09DXdEX8Md0ddwN+7Q047W79KNzmvXrq3OnTtr8+bNtnNFRUXavHmz3WyoyyksLNTXX3+tsLCwyioTAAAAAAAAFczly/emTp2qkSNHqkuXLuratav+/ve/Kzc3V6NHj5YkjRgxQo0bN9bcuXMlSbNnz9Ytt9yi1q1b6+zZs3rxxRf1448/6uGHH3bl1wAAAAAAAIATXB5K3X///frll180Y8YMpaen68Ybb9SmTZsUEhIiSTp58qQ8PP47oeu3337T2LFjlZ6ervr166tz587auXOnIiIiXPUVAAAAAAAA4CSXh1KSNGHCBE2YMKHUa4mJiXbHCxcu1MKFC02oCgAAAAAAAJXFpXtKAQAAAAAAoGYilAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpAAAAAAAAmI5QCgAAAAAAAKar5eoCUD6FRYaSUjOVkZOvYH8fdQ0PkqeHxdVlAQAAAAAAOIRQqhralJKm+A1HlJaVbzsXFuijmQMi1C8yzIWVAQAAAAAAOIble9XMppQ0jVtxwC6QkqT0rHyNW3FAm1LSXFQZAAAAAACA4wilqpHCIkPxG47IKOVa8bn4DUdUWFTaCAAAAAAAgKqDUKoaSUrNLDFD6lKGpLSsfCWlZppXFAAAAAAAQDkQSlUjGTllB1LlGQcAAAAAAOAqhFLVSLC/T4WOAwAAAAAAcBVCqWqka3iQwgJ9ZCnjukUXn8LXNTzIzLIAAAAAAACcRihVjXh6WDRzQIQklQimio9nDoiQp0dZsRUAAAAAAEDVQChVzfSLDNOS4Z0UGmi/RC800EdLhndSv8gwF1UGAAAAAADguFquLgDO6xcZpj4RoUpKzVRGTr6C/S8u2WOGFAAAAAAAqC4IpaopTw+Lolo1cHUZAAAAAAAA5cLyPQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYDpCKQAAAAAAAJiOUAoAAAAAAACmI5QCAAAAAACA6QilAAAAAAAAYLpari7AbIZhSJKys7NdXAlqIqvVqry8PGVnZ8vLy8vV5QAVgr6Gu6Gn4Y7oa7gj+hruxp16ujhzKc5gylLjQqmcnBxJUtOmTV1cCQAAAAAAgPvKyclRYGBgmdctxpViKzdTVFSkn3/+Wf7+/rJYLK4uBzVMdna2mjZtqp9++kkBAQGuLgeoEPQ13A09DXdEX8Md0ddwN+7U04ZhKCcnR40aNZKHR9k7R9W4mVIeHh5q0qSJq8tADRcQEFDt/yUD/BF9DXdDT8Md0ddwR/Q13I279PTlZkgVY6NzAAAAAAAAmI5QCgAAAAAAAKYjlAJM5O3trZkzZ8rb29vVpQAVhr6Gu6Gn4Y7oa7gj+hrupib2dI3b6BwAAAAAAACux0wpAAAAAAAAmI5QCgAAAAAAAKYjlAIAAAAAAIDpCKUAAAAAAABgOkIpoILNnTtXN910k/z9/RUcHKyBAwfq2LFjdmPy8/M1fvx4NWjQQHXr1tU999yj06dPu6hiwHkvvPCCLBaLJk+ebDtHX6M6OnXqlIYPH64GDRrI19dX119/vfbt22e7bhiGZsyYobCwMPn6+qp37946fvy4CysGylZYWKjp06crPDxcvr6+atWqlebMmaNLn2tET6Oq27ZtmwYMGKBGjRrJYrFo/fr1dtcd6eHMzEwNGzZMAQEBqlevnh566CGdO3fOxG8B2LtcX1utVj311FO6/vrrVadOHTVq1EgjRozQzz//bPce7trXhFJABfvyyy81fvx47d69WwkJCbJarerbt69yc3NtY6ZMmaINGzZo7dq1+vLLL/Xzzz/r7rvvdmHVgOP27t2r119/XR06dLA7T1+juvntt9/UrVs3eXl5aePGjTpy5IgWLFig+vXr28bMnz9fixYt0tKlS7Vnzx7VqVNHcXFxys/Pd2HlQOnmzZunJUuW6NVXX9XRo0c1b948zZ8/X6+88optDD2Nqi43N1c33HCDFi9eXOp1R3p42LBhOnz4sBISEvTpp59q27Zt+vOf/2zWVwBKuFxf5+Xl6cCBA5o+fboOHDigf/7znzp27Jj+9Kc/2Y1z2742AFSqjIwMQ5Lx5ZdfGoZhGGfPnjW8vLyMtWvX2sYcPXrUkGTs2rXLVWUCDsnJyTHatGljJCQkGDExMcakSZMMw6CvUT099dRTRvfu3cu8XlRUZISGhhovvvii7dzZs2cNb29v4/333zejRMApd9xxhzFmzBi7c3fffbcxbNgwwzDoaVQ/kox169bZjh3p4SNHjhiSjL1799rGbNy40bBYLMapU6dMqx0oyx/7ujRJSUmGJOPHH380DMO9+5qZUkAly8rKkiQFBQVJkvbv3y+r1arevXvbxrRt21bNmjXTrl27XFIj4Kjx48frjjvusOtfib5G9fTJJ5+oS5cuGjx4sIKDg9WxY0e98cYbtuupqalKT0+36+vAwEDdfPPN9DWqpOjoaG3evFnffvutJOnQoUPasWOH+vfvL4meRvXnSA/v2rVL9erVU5cuXWxjevfuLQ8PD+3Zs8f0moHyyMrKksViUb169SS5d1/XcnUBgDsrKirS5MmT1a1bN0VGRkqS0tPTVbt2bdu/YIqFhIQoPT3dBVUCjvnggw904MAB7d27t8Q1+hrV0Q8//KAlS5Zo6tSpeuaZZ7R3715NnDhRtWvX1siRI229GxISYncffY2q6umnn1Z2drbatm0rT09PFRYW6rnnntOwYcMkiZ5GtedID6enpys4ONjueq1atRQUFESfo1rIz8/XU089paFDhyogIECSe/c1oRRQicaPH6+UlBTt2LHD1aUAV+Wnn37SpEmTlJCQIB8fH1eXA1SIoqIidenSRc8//7wkqWPHjkpJSdHSpUs1cuRIF1cHOG/NmjVauXKlVq1apfbt2ys5OVmTJ09Wo0aN6GkAqAasVqvuu+8+GYahJUuWuLocU7B8D6gkEyZM0KeffqqtW7eqSZMmtvOhoaG6cOGCzp49azf+9OnTCg0NNblKwDH79+9XRkaGOnXqpFq1aqlWrVr68ssvtWjRItWqVUshISH0NaqdsLAwRURE2J1r166dTp48KUm23v3jUyTpa1RVTzzxhJ5++mkNGTJE119/vR588EFNmTJFc+fOlURPo/pzpIdDQ0OVkZFhd/33339XZmYmfY4qrTiQ+vHHH5WQkGCbJSW5d18TSgEVzDAMTZgwQevWrdOWLVsUHh5ud71z587y8vLS5s2bbeeOHTumkydPKioqyuxyAYf06tVLX3/9tZKTk22vLl26aNiwYbZ/pq9R3XTr1k3Hjh2zO/ftt9+qefPmkqTw8HCFhoba9XV2drb27NlDX6NKysvLk4eH/V/vPT09VVRUJImeRvXnSA9HRUXp7Nmz2r9/v23Mli1bVFRUpJtvvtn0mgFHFAdSx48f1xdffKEGDRrYXXfnvmb5HlDBxo8fr1WrVunjjz+Wv7+/bY1vYGCgfH19FRgYqIceekhTp05VUFCQAgIC9PjjjysqKkq33HKLi6sHSufv72/bF61YnTp11KBBA9t5+hrVzZQpUxQdHa3nn39e9913n5KSkrRs2TItW7ZMkmSxWDR58mT99a9/VZs2bRQeHq7p06erUaNGGjhwoGuLB0oxYMAAPffcc2rWrJnat2+vgwcP6m9/+5vGjBkjiZ5G9XDu3Dl99913tuPU1FQlJycrKChIzZo1u2IPt2vXTv369dPYsWO1dOlSWa1WTZgwQUOGDFGjRo1c9K1Q012ur8PCwnTvvffqwIED+vTTT1VYWGj7f8igoCDVrl3bvfva1Y//A9yNpFJfb7/9tm3M+fPnjccee8yoX7++4efnZwwaNMhIS0tzXdFAOcTExBiTJk2yHdPXqI42bNhgREZGGt7e3kbbtm2NZcuW2V0vKioypk+fboSEhBje3t5Gr169jGPHjrmoWuDysrOzjUmTJhnNmjUzfHx8jJYtWxr/+7//axQUFNjG0NOo6rZu3Vrq36VHjhxpGIZjPXzmzBlj6NChRt26dY2AgABj9OjRRk5Ojgu+DXDR5fo6NTW1zP+H3Lp1q+093LWvLYZhGGaGYAAAAAAAAAB7SgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAAAAAMB0hFIAAAAAAAAwHaEUAAAAAAAATEcoBQAAAAAAANMRSgEAAFSiX375RePGjVOzZs3k7e2t0NBQxcXF6auvvpIkWSwWrV+/3rVFAgAAuEAtVxcAAADgzu655x5duHBB77zzjlq2bKnTp09r8+bNOnPmjKtLAwAAcClmSgEAAFSSs2fPavv27Zo3b55iY2PVvHlzde3aVdOmTdOf/vQntWjRQpI0aNAgWSwW27Ekffzxx+rUqZN8fHzUsmVLxcfH6/fff7ddt1gsWrJkifr37y9fX1+1bNlSH374oe36hQsXNGHCBIWFhcnHx0fNmzfX3LlzzfrqAAAAV0QoBQAAUEnq1q2runXrav369SooKChxfe/evZKkt99+W2lpabbj7du3a8SIEZo0aZKOHDmi119/XcuXL9dzzz1nd//06dN1zz336NChQxo2bJiGDBmio0ePSpIWLVqkTz75RGvWrNGxY8e0cuVKu9ALAADA1SyGYRiuLgIAAMBdffTRRxo7dqzOnz+vTp06KSYmRkOGDFGHDh0kXZzxtG7dOg0cONB2T+/evdWrVy9NmzbNdm7FihV68skn9fPPP9vue/TRR7VkyRLbmFtuuUWdOnXSa6+9pokTJ+rw4cP64osvZLFYzPmyAAAATmCmFAAAQCW655579PPPP+uTTz5Rv379lJiYqE6dOmn58uVl3nPo0CHNnj3bNtOqbt26Gjt2rNLS0pSXl2cbFxUVZXdfVFSUbabUqFGjlJycrOuuu04TJ07U559/XinfDwAAoLwIpQAAACqZj4+P+vTpo+nTp2vnzp0aNWqUZs6cWeb4c+fOKT4+XsnJybbX119/rePHj8vHx8ehz+zUqZNSU1M1Z84cnT9/Xvfdd5/uvffeivpKAAAAV41QCgAAwGQRERHKzc2VJHl5eamwsNDueqdOnXTs2DG1bt26xMvD479/fdu9e7fdfbt371a7du1sxwEBAbr//vv1xhtvaPXq1froo4+UmZlZid8MAADAcbVcXQAAAIC7OnPmjAYPHqwxY8aoQ4cO8vf31759+zR//nzdddddkqQWLVpo8+bN6tatm7y9vVW/fn3NmDFDd955p5o1a6Z7771XHh4eOnTokFJSUvTXv/7V9v5r165Vly5d1L17d61cuVJJSUl66623JEl/+9vfFBYWpo4dO8rDw0Nr165VaGio6tWr54ofBQAAQAmEUgAAAJWkbt26uvnmm7Vw4UJ9//33slqtatq0qcaOHatnnnlGkrRgwQJNnTpVb7zxhho3bqwTJ04oLi5On376qWbPnq158+bJy8tLbdu21cMPP2z3/vHx8frggw/02GOPKSwsTO+//74iIiIkSf7+/po/f76OHz8uT09P3XTTTfr3v/9tN9MKAADAlXj6HgAAQDVU2lP7AAAAqhN+VQYAAAAAAADTEUoBAAAAAADAdOwpBQAAUA2xAwMAAKjumCkFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0xFKAQAAAAAAwHSEUgAAAAAAADAdoRQAAAAAAABMRygFAAAAAAAA0/0/4yaw2avz3NQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot WER over training steps\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot WER\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(trainer_history['step'], trainer_history['eval_wer'], marker='o', label='WER')\n",
    "plt.title(\"WER over Training Steps\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"WER Evaluation\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and processor loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
    "\n",
    "# Define the path to the model checkpoint\n",
    "model_path = \"./whisper-small-ger-lr6.25-adv/checkpoint-8\"\n",
    "\n",
    "# Load the best fine-tuned model\n",
    "try:\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(model_path).to(device)\n",
    "    processor = WhisperProcessor.from_pretrained(model_path)\n",
    "    print(\"Model and processor loaded successfully.\")\n",
    "except OSError as e:\n",
    "    print(f\"Error loading model or processor: {e}\")\n",
    "\n",
    "# Inference function\n",
    "# Inference function with language token\n",
    "def transcribe(audio):\n",
    "    input_features = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"], return_tensors=\"pt\").input_features.to(device)\n",
    "    forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"de\", task=\"transcribe\")\n",
    "    predicted_ids = model.generate(input_features, forced_decoder_ids=forced_decoder_ids)\n",
    "    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
    "    return transcription[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Result\n",
    "\n",
    "we got 1.0117 seconds for best inference and avg wer of 0.4%. Yeay!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "Reference: ich würde gerne meinen aktuellen Kontostand einsehen\n",
      "Prediction: ich würde gerne meinen aktuellen kontostand einzahlen\n",
      "Inference time: 1.0117 seconds\n",
      "\n",
      "Sample 2:\n",
      "Reference: Hallo ich bin am Wochenende nach Warschau und habe meine Bank geguckt geschrieben gewechselt und wollte nur sicher gehen dass ich meine Kreditkarte dann auch da benutzen kann\n",
      "Prediction: hallo ich bin ein wochen um nach wasch auf und habe meine bankkreditkarte zu ihnen gewechselt und wollte mir sichergehen dass ich meine kreditkarte dann auch da benutzen kann\n",
      "Inference time: 2.7010 seconds\n",
      "\n",
      "Sample 3:\n",
      "Reference: Hallo ich habe eine Frage wo kann ich denn überall Geld einzahlen ich habe mal gesehen was kann das in den Supermärkten eventuell die ausgewiesen gibt's da noch mehr stellen\n",
      "Prediction: hallo ich habe eine frage wo kann ich denn überall geld einzahlen ich habe mal gesehen man kann das in den supermärkten und baumärkten eventuell die ausgewählten einzahlen gibt es da noch mehr stellen\n",
      "Inference time: 3.3424 seconds\n",
      "\n",
      "WER for 3 samples: 0.4\n"
     ]
    }
   ],
   "source": [
    "# Run inference on three samples\n",
    "for i in range(3):\n",
    "    sample = ds2[\"test\"][i]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    transcription = transcribe(sample[\"audio\"])\n",
    "    end_time = time.time()\n",
    "    \n",
    "    inference_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"Reference: {sample['transcription']}\")\n",
    "    print(f\"Prediction: {transcription}\")\n",
    "    print(f\"Inference time: {inference_time:.4f} seconds\")\n",
    "    print()\n",
    "\n",
    "# Calculate overall WER for these three samples\n",
    "wer = metric.compute(predictions=[transcribe(ds2[\"test\"][i][\"audio\"]) for i in range(3)],\n",
    "                     references=[ds2[\"test\"][i][\"transcription\"] for i in range(3)])\n",
    "print(f\"WER for 3 samples: {wer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Little Bit of Demo for Spice it up\n",
    "ps try to speak in german and let the fine tune model transcribe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording finished.\n",
      "Transcription: hallo mein name ist sabir und ich studiere jes kundschiller intelligence\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "\n",
    "# Function to record audio from the microphone\n",
    "def record_audio(duration, sample_rate=16000):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype='float32')\n",
    "    sd.wait()  # Wait until the recording is finished\n",
    "    print(\"Recording finished.\")\n",
    "    audio = np.squeeze(audio)  # Remove single-dimensional entries\n",
    "    return {\"array\": audio, \"sampling_rate\": sample_rate}\n",
    "\n",
    "# Record audio from the microphone\n",
    "duration = 10  # Record for 5 seconds\n",
    "audio = record_audio(duration)\n",
    "\n",
    "# Transcribe the recorded audio\n",
    "transcription = transcribe(audio)\n",
    "print(\"Transcription:\", transcription)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pr3_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
