{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcription bare metal fine tuning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep for device config(device type = arm mac sillicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install --upgrade datasets[audio] transformers accelerate evaluate jiwer tensorboard gradio\n",
    "import os \n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mps config\n",
    "import torch\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.backends.mps.is_available() else torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Into train, test, and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['filepath', 'text_asr', 'text_translated', 'intent'],\n",
      "        num_rows: 488\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['filepath', 'text_asr', 'text_translated', 'intent'],\n",
      "        num_rows: 62\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['filepath', 'text_asr', 'text_translated', 'intent'],\n",
      "        num_rows: 61\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(36422) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(36423) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "minds_de_ds = load_dataset('csv', data_files='./MInDS-14/text/de-DE.csv')\n",
    "\n",
    "train_testvalid = minds_de_ds['train'].train_test_split(test_size=0.2)\n",
    "# Split the 10% test + valid in half test, half valid\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5)\n",
    "# gather everyone if you want to have a single DatasetDict\n",
    "ds = DatasetDict({\n",
    "    'train': train_testvalid['train'],\n",
    "    'test': test_valid['test'],\n",
    "    'valid': test_valid['train']})\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "\n",
    "def load_audio_data(batch, audio_base_path):\n",
    "    audio_files = [os.path.join(audio_base_path, filepath) for filepath in batch['filepath']]\n",
    "    audio_data = [librosa.load(file_path, sr=None) for file_path in audio_files]\n",
    "    \n",
    "    # Separate audio data and sample rates\n",
    "    audio_signals = [data[0] for data in audio_data]\n",
    "    sample_rates = [data[1] for data in audio_data]\n",
    "    \n",
    "    batch['audio'] = [{'path': file_path, 'array': audio, 'sampling_rate': sr} for file_path, audio, sr in zip(audio_files, audio_signals, sample_rates)]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/488 [00:00<?, ? examples/s]python(36424) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(36425) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Map: 100%|██████████| 488/488 [00:01<00:00, 296.22 examples/s]\n",
      "Map: 100%|██████████| 62/62 [00:00<00:00, 241.97 examples/s]\n",
      "Map: 100%|██████████| 61/61 [00:00<00:00, 328.64 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['filepath', 'text_asr', 'text_translated', 'intent', 'audio'],\n",
      "        num_rows: 488\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['filepath', 'text_asr', 'text_translated', 'intent', 'audio'],\n",
      "        num_rows: 62\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['filepath', 'text_asr', 'text_translated', 'intent', 'audio'],\n",
      "        num_rows: 61\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to load audio data and add it to the dataset\n",
    "audio_base_path = \"./MInDS-14/audio\"\n",
    "ds = ds.map(load_audio_data, fn_kwargs={'audio_base_path': audio_base_path}, batched=True)\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the specified columns\n",
    "ds = ds.remove_columns([\"filepath\",\"text_translated\", \"intent\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "\n",
    "ds = ds.cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "ds2 = ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperFeatureExtractor, WhisperTokenizer, WhisperProcessor\n",
    "MODEL_NAME = \"openai/whisper-small\"\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(MODEL_NAME)\n",
    "tokenizer = WhisperTokenizer.from_pretrained(MODEL_NAME, language=\"german\", task=\"transcribe\")\n",
    "processor = WhisperProcessor.from_pretrained(MODEL_NAME, language=\"german\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text_asr': 'hallo guten Morgen können Sie mir bitte meinen aktuellen Kontostand mitteilen', 'audio': {'path': None, 'array': array([0.00025965, 0.00029964, 0.00022703, ..., 0.00027563, 0.00022646,\n",
      "       0.0001217 ]), 'sampling_rate': 16000}}\n"
     ]
    }
   ],
   "source": [
    "print(ds[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    # load and resample audio data from 48 to 16kHz\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array\n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "    # encode target text to label ids\n",
    "    batch[\"labels\"] = tokenizer(batch[\"text_asr\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(36458) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(36459) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(36460) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(36461) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Map (num_proc=4):   0%|          | 0/488 [00:00<?, ? examples/s]python(36462) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Map (num_proc=4): 100%|██████████| 488/488 [00:13<00:00, 37.52 examples/s] \n",
      "python(36463) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(36464) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(36465) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(36466) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Map (num_proc=4):   0%|          | 0/62 [00:00<?, ? examples/s]python(36467) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Map (num_proc=4): 100%|██████████| 62/62 [00:01<00:00, 45.43 examples/s]\n",
      "python(36469) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(36470) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(36471) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(36472) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Map (num_proc=4):   0%|          | 0/61 [00:00<?, ? examples/s]python(36473) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Map (num_proc=4): 100%|██████████| 61/61 [00:01<00:00, 41.66 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds = ds.map(prepare_dataset, remove_columns=ds.column_names[\"train\"], num_proc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Model and  the Config For Speccific Cases(german & transcribe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(MODEL_NAME).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generation_config.language = \"german\"\n",
    "model.generation_config.task = \"transcribe\"\n",
    "model.generation_config.forced_decoder_ids = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Data Colator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "    decoder_start_token_id: int\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
    "    processor=processor,\n",
    "    decoder_start_token_id=model.config.decoder_start_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Metrics (WER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training args & Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./whisper-small-ger-lr1.5\",  \n",
    "    gradient_accumulation_steps=2,  # increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=4,\n",
    "    max_steps=61,\n",
    "    gradient_checkpointing=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    save_steps=8,\n",
    "    eval_steps=8,\n",
    "    logging_steps=8,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/61 [00:00<?, ?it/s]Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n",
      " 13%|█▎        | 8/61 [01:49<11:53, 13.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9583, 'grad_norm': 11.097613334655762, 'learning_rate': 9.298245614035088e-06, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, 50259], [2, 50359], [3, 50363]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "                                              \n",
      " 13%|█▎        | 8/61 [03:00<11:53, 13.46s/it]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6262494325637817, 'eval_wer': 19.68365553602812, 'eval_runtime': 71.6204, 'eval_samples_per_second': 0.866, 'eval_steps_per_second': 0.112, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 16/61 [06:22<16:28, 21.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.529, 'grad_norm': 7.425166130065918, 'learning_rate': 7.894736842105265e-06, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 26%|██▌       | 16/61 [07:28<16:28, 21.96s/it]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.41484466195106506, 'eval_wer': 17.04745166959578, 'eval_runtime': 66.3286, 'eval_samples_per_second': 0.935, 'eval_steps_per_second': 0.121, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 24/61 [09:18<08:54, 14.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3983, 'grad_norm': 7.24657678604126, 'learning_rate': 6.491228070175439e-06, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 39%|███▉      | 24/61 [10:18<08:54, 14.45s/it]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3997698724269867, 'eval_wer': 15.905096660808434, 'eval_runtime': 59.4548, 'eval_samples_per_second': 1.043, 'eval_steps_per_second': 0.135, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 32/61 [11:59<06:34, 13.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3421, 'grad_norm': 6.3821868896484375, 'learning_rate': 5.087719298245615e-06, 'epoch': 1.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 52%|█████▏    | 32/61 [12:58<06:34, 13.62s/it]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.38299596309661865, 'eval_wer': 15.641476274165203, 'eval_runtime': 58.4402, 'eval_samples_per_second': 1.061, 'eval_steps_per_second': 0.137, 'epoch': 1.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 40/61 [14:42<04:54, 14.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2149, 'grad_norm': 3.1096808910369873, 'learning_rate': 3.6842105263157896e-06, 'epoch': 1.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 66%|██████▌   | 40/61 [15:40<04:54, 14.01s/it]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3769168555736542, 'eval_wer': 16.16871704745167, 'eval_runtime': 57.5948, 'eval_samples_per_second': 1.076, 'eval_steps_per_second': 0.139, 'epoch': 1.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 48/61 [17:18<02:56, 13.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2295, 'grad_norm': 3.5152502059936523, 'learning_rate': 2.280701754385965e-06, 'epoch': 1.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 79%|███████▊  | 48/61 [18:15<02:56, 13.55s/it]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.37503522634506226, 'eval_wer': 16.34446397188049, 'eval_runtime': 56.891, 'eval_samples_per_second': 1.09, 'eval_steps_per_second': 0.141, 'epoch': 1.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 56/61 [19:54<01:08, 13.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.223, 'grad_norm': 4.282607555389404, 'learning_rate': 8.771929824561404e-07, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 92%|█████████▏| 56/61 [20:51<01:08, 13.61s/it]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3725997507572174, 'eval_wer': 16.34446397188049, 'eval_runtime': 56.5333, 'eval_samples_per_second': 1.097, 'eval_steps_per_second': 0.142, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [21:54<00:00, 16.44s/it]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n",
      "100%|██████████| 61/61 [21:59<00:00, 21.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1319.5521, 'train_samples_per_second': 0.74, 'train_steps_per_second': 0.046, 'train_loss': 0.40416934060268717, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=61, training_loss=0.40416934060268717, metrics={'train_runtime': 1319.5521, 'train_samples_per_second': 0.74, 'train_steps_per_second': 0.046, 'total_flos': 2.8165935071232e+17, 'train_loss': 0.40416934060268717, 'epoch': 2.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model for inference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(training_args.output_dir)\n",
    "processor.save_pretrained(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>grad_norm</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_wer</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>train_runtime</th>\n",
       "      <th>train_samples_per_second</th>\n",
       "      <th>train_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9583</td>\n",
       "      <td>11.097613</td>\n",
       "      <td>9.298246e-06</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>8</td>\n",
       "      <td>0.626249</td>\n",
       "      <td>19.683656</td>\n",
       "      <td>71.6204</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5290</td>\n",
       "      <td>7.425166</td>\n",
       "      <td>7.894737e-06</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>16</td>\n",
       "      <td>0.414845</td>\n",
       "      <td>17.047452</td>\n",
       "      <td>66.3286</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3983</td>\n",
       "      <td>7.246577</td>\n",
       "      <td>6.491228e-06</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>24</td>\n",
       "      <td>0.399770</td>\n",
       "      <td>15.905097</td>\n",
       "      <td>59.4548</td>\n",
       "      <td>1.043</td>\n",
       "      <td>0.135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.3421</td>\n",
       "      <td>6.382187</td>\n",
       "      <td>5.087719e-06</td>\n",
       "      <td>1.049180</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.049180</td>\n",
       "      <td>32</td>\n",
       "      <td>0.382996</td>\n",
       "      <td>15.641476</td>\n",
       "      <td>58.4402</td>\n",
       "      <td>1.061</td>\n",
       "      <td>0.137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.2149</td>\n",
       "      <td>3.109681</td>\n",
       "      <td>3.684211e-06</td>\n",
       "      <td>1.311475</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.311475</td>\n",
       "      <td>40</td>\n",
       "      <td>0.376917</td>\n",
       "      <td>16.168717</td>\n",
       "      <td>57.5948</td>\n",
       "      <td>1.076</td>\n",
       "      <td>0.139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.2295</td>\n",
       "      <td>3.515250</td>\n",
       "      <td>2.280702e-06</td>\n",
       "      <td>1.573770</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.573770</td>\n",
       "      <td>48</td>\n",
       "      <td>0.375035</td>\n",
       "      <td>16.344464</td>\n",
       "      <td>56.8910</td>\n",
       "      <td>1.090</td>\n",
       "      <td>0.141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.2230</td>\n",
       "      <td>4.282608</td>\n",
       "      <td>8.771930e-07</td>\n",
       "      <td>1.836066</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.836066</td>\n",
       "      <td>56</td>\n",
       "      <td>0.372600</td>\n",
       "      <td>16.344464</td>\n",
       "      <td>56.5333</td>\n",
       "      <td>1.097</td>\n",
       "      <td>0.142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1319.5521</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.046</td>\n",
       "      <td>2.816594e+17</td>\n",
       "      <td>0.404169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      loss  grad_norm  learning_rate     epoch  step  eval_loss   eval_wer  \\\n",
       "0   0.9583  11.097613   9.298246e-06  0.262295     8        NaN        NaN   \n",
       "1      NaN        NaN            NaN  0.262295     8   0.626249  19.683656   \n",
       "2   0.5290   7.425166   7.894737e-06  0.524590    16        NaN        NaN   \n",
       "3      NaN        NaN            NaN  0.524590    16   0.414845  17.047452   \n",
       "4   0.3983   7.246577   6.491228e-06  0.786885    24        NaN        NaN   \n",
       "5      NaN        NaN            NaN  0.786885    24   0.399770  15.905097   \n",
       "6   0.3421   6.382187   5.087719e-06  1.049180    32        NaN        NaN   \n",
       "7      NaN        NaN            NaN  1.049180    32   0.382996  15.641476   \n",
       "8   0.2149   3.109681   3.684211e-06  1.311475    40        NaN        NaN   \n",
       "9      NaN        NaN            NaN  1.311475    40   0.376917  16.168717   \n",
       "10  0.2295   3.515250   2.280702e-06  1.573770    48        NaN        NaN   \n",
       "11     NaN        NaN            NaN  1.573770    48   0.375035  16.344464   \n",
       "12  0.2230   4.282608   8.771930e-07  1.836066    56        NaN        NaN   \n",
       "13     NaN        NaN            NaN  1.836066    56   0.372600  16.344464   \n",
       "14     NaN        NaN            NaN  2.000000    61        NaN        NaN   \n",
       "\n",
       "    eval_runtime  eval_samples_per_second  eval_steps_per_second  \\\n",
       "0            NaN                      NaN                    NaN   \n",
       "1        71.6204                    0.866                  0.112   \n",
       "2            NaN                      NaN                    NaN   \n",
       "3        66.3286                    0.935                  0.121   \n",
       "4            NaN                      NaN                    NaN   \n",
       "5        59.4548                    1.043                  0.135   \n",
       "6            NaN                      NaN                    NaN   \n",
       "7        58.4402                    1.061                  0.137   \n",
       "8            NaN                      NaN                    NaN   \n",
       "9        57.5948                    1.076                  0.139   \n",
       "10           NaN                      NaN                    NaN   \n",
       "11       56.8910                    1.090                  0.141   \n",
       "12           NaN                      NaN                    NaN   \n",
       "13       56.5333                    1.097                  0.142   \n",
       "14           NaN                      NaN                    NaN   \n",
       "\n",
       "    train_runtime  train_samples_per_second  train_steps_per_second  \\\n",
       "0             NaN                       NaN                     NaN   \n",
       "1             NaN                       NaN                     NaN   \n",
       "2             NaN                       NaN                     NaN   \n",
       "3             NaN                       NaN                     NaN   \n",
       "4             NaN                       NaN                     NaN   \n",
       "5             NaN                       NaN                     NaN   \n",
       "6             NaN                       NaN                     NaN   \n",
       "7             NaN                       NaN                     NaN   \n",
       "8             NaN                       NaN                     NaN   \n",
       "9             NaN                       NaN                     NaN   \n",
       "10            NaN                       NaN                     NaN   \n",
       "11            NaN                       NaN                     NaN   \n",
       "12            NaN                       NaN                     NaN   \n",
       "13            NaN                       NaN                     NaN   \n",
       "14      1319.5521                      0.74                   0.046   \n",
       "\n",
       "      total_flos  train_loss  \n",
       "0            NaN         NaN  \n",
       "1            NaN         NaN  \n",
       "2            NaN         NaN  \n",
       "3            NaN         NaN  \n",
       "4            NaN         NaN  \n",
       "5            NaN         NaN  \n",
       "6            NaN         NaN  \n",
       "7            NaN         NaN  \n",
       "8            NaN         NaN  \n",
       "9            NaN         NaN  \n",
       "10           NaN         NaN  \n",
       "11           NaN         NaN  \n",
       "12           NaN         NaN  \n",
       "13           NaN         NaN  \n",
       "14  2.816594e+17    0.404169  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "trainer_history = pd.DataFrame(trainer.state.log_history)\n",
    "trainer_history.groupby('step').first().reset_index()\n",
    "trainer_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Lowest Wer scores actualy at the early phase of training and continue rose up until step XX and start declining! WER: XX%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot WER over training steps\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot WER\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(trainer_history['step'], trainer_history['eval_wer'], marker='o', label='WER')\n",
    "plt.title(\"WER over Training Steps\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"WER Evaluation\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and processor loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
    "\n",
    "# Define the path to the model checkpoint\n",
    "model_path = \"./whisper-small-ger-lr1.5\"\n",
    "\n",
    "# Load the best fine-tuned model\n",
    "try:\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(model_path)\n",
    "    processor = WhisperProcessor.from_pretrained(model_path)\n",
    "    print(\"Model and processor loaded successfully.\")\n",
    "except OSError as e:\n",
    "    print(f\"Error loading model or processor: {e}\")\n",
    "\n",
    "# Inference function\n",
    "def transcribe(audio):\n",
    "    input_features = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"], return_tensors=\"pt\").input_features\n",
    "    predicted_ids = model.generate(input_features)\n",
    "    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
    "    return transcription[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Result\n",
    "\n",
    "we got 0.5741 seconds for best inference and avg wer of 0.106%. Yeay!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Little Bit of Demo for Spice it up\n",
    "ps try to speak in german and let the fine tune model transcribe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "Reference: Hallo ich versuche gerade auf meine bank wir wäre meines abzubekommen und ich komme einfach nicht dran rein können Sie mir da helfen bitte\n",
      "Prediction: Hallo ich versuche gerade auf meine Bank wie wer meines abzubekommen und ich komme einfach nicht rein können Sie mir da helfen bitte\n",
      "Inference time: 3.2295 seconds\n",
      "\n",
      "Sample 2:\n",
      "Reference: ja schönen guten Tag ich wollte mich mal erkundigen nach einem Kredit die nicht aufgenommen hatte schon meine Firma\n",
      "Prediction: ja schönen guten Tag ich wollte mich mal erkundigen nach einem Kredit die nicht aufgenommen hatte für meine Firma\n",
      "Inference time: 0.8977 seconds\n",
      "\n",
      "Sample 3:\n",
      "Reference: zeig mir meine Lastschriften\n",
      "Prediction: zeig mir meine Lastschriften\n",
      "Inference time: 0.5741 seconds\n",
      "\n",
      "WER for 3 samples: 0.10638297872340426\n"
     ]
    }
   ],
   "source": [
    "# Run inference on three samples\n",
    "for i in range(3):\n",
    "    sample = ds2[\"test\"][i]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    transcription = transcribe(sample[\"audio\"])\n",
    "    end_time = time.time()\n",
    "    \n",
    "    inference_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"Reference: {sample['text_asr']}\")\n",
    "    print(f\"Prediction: {transcription}\")\n",
    "    print(f\"Inference time: {inference_time:.4f} seconds\")\n",
    "    print()\n",
    "\n",
    "# Calculate overall WER for these three samples\n",
    "wer = metric.compute(predictions=[transcribe(ds2[\"test\"][i][\"audio\"]) for i in range(3)],\n",
    "                     references=[ds2[\"test\"][i][\"text_asr\"] for i in range(3)])\n",
    "print(f\"WER for 3 samples: {wer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sounddevice in /opt/anaconda3/envs/pr3_venv/lib/python3.10/site-packages (0.4.7)\n",
      "Requirement already satisfied: CFFI>=1.0 in /opt/anaconda3/envs/pr3_venv/lib/python3.10/site-packages (from sounddevice) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/envs/pr3_venv/lib/python3.10/site-packages (from CFFI>=1.0->sounddevice) (2.22)\n"
     ]
    }
   ],
   "source": [
    "# !pip install sounddevice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Little Bit of Demo for Spice it up\n",
    "ps try to speak in german and let the fine tune model transcribe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording finished.\n",
      "Transcription: Hallo ich nehme Schobir\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "\n",
    "# Function to record audio from the microphone\n",
    "def record_audio(duration, sample_rate=16000):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype='float32')\n",
    "    sd.wait()  # Wait until the recording is finished\n",
    "    print(\"Recording finished.\")\n",
    "    audio = np.squeeze(audio)  # Remove single-dimensional entries\n",
    "    return {\"array\": audio, \"sampling_rate\": sample_rate}\n",
    "\n",
    "# Record audio from the microphone\n",
    "duration = 5  # Record for 5 seconds\n",
    "audio = record_audio(duration)\n",
    "\n",
    "# Transcribe the recorded audio\n",
    "transcription = transcribe(audio)\n",
    "print(\"Transcription:\", transcription)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pr3_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
