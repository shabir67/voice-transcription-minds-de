{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/anaconda3/envs/pr3_venv/lib/python3.10/site-packages (24.2)\n",
      "zsh:1: no matches found: datasets[audio]\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install --upgrade datasets[audio] transformers accelerate evaluate jiwer tensorboard gradio\n",
    "PYTORCH_ENABLE_MPS_FALLBACK=1\n",
    "PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['filepath', 'text_asr', 'text_translated', 'intent'],\n",
      "        num_rows: 488\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['filepath', 'text_asr', 'text_translated', 'intent'],\n",
      "        num_rows: 62\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['filepath', 'text_asr', 'text_translated', 'intent'],\n",
      "        num_rows: 61\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "minds_de_ds = load_dataset('csv', data_files='./MInDS-14/text/de-DE.csv')\n",
    "\n",
    "train_testvalid = minds_de_ds['train'].train_test_split(test_size=0.2)\n",
    "# Split the 10% test + valid in half test, half valid\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5)\n",
    "# gather everyone if you want to have a single DatasetDict\n",
    "ds = DatasetDict({\n",
    "    'train': train_testvalid['train'],\n",
    "    'test': test_valid['test'],\n",
    "    'valid': test_valid['train']})\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "\n",
    "def load_audio_data(batch, audio_base_path):\n",
    "    audio_files = [os.path.join(audio_base_path, filepath) for filepath in batch['filepath']]\n",
    "    audio_data = [librosa.load(file_path, sr=None) for file_path in audio_files]\n",
    "    \n",
    "    # Separate audio data and sample rates\n",
    "    audio_signals = [data[0] for data in audio_data]\n",
    "    sample_rates = [data[1] for data in audio_data]\n",
    "    \n",
    "    batch['audio'] = [{'path': file_path, 'array': audio, 'sampling_rate': sr} for file_path, audio, sr in zip(audio_files, audio_signals, sample_rates)]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 488/488 [00:00<00:00, 1211.32 examples/s]\n",
      "Map: 100%|██████████| 62/62 [00:00<00:00, 1115.63 examples/s]\n",
      "Map: 100%|██████████| 61/61 [00:00<00:00, 1401.08 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['filepath', 'text_asr', 'text_translated', 'intent', 'audio'],\n",
      "        num_rows: 488\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['filepath', 'text_asr', 'text_translated', 'intent', 'audio'],\n",
      "        num_rows: 62\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['filepath', 'text_asr', 'text_translated', 'intent', 'audio'],\n",
      "        num_rows: 61\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to load audio data and add it to the dataset\n",
    "audio_base_path = \"./MInDS-14/audio\"\n",
    "ds = ds.map(load_audio_data, fn_kwargs={'audio_base_path': audio_base_path}, batched=True)\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the specified columns\n",
    "ds = ds.remove_columns([\"filepath\",\"text_translated\", \"intent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "\n",
    "ds = ds.cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "ds2 = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mps config\n",
    "import torch\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.backends.mps.is_available() else torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperFeatureExtractor, WhisperTokenizer, WhisperProcessor\n",
    "MODEL_NAME = \"openai/whisper-large-v3\"\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(MODEL_NAME)\n",
    "tokenizer = WhisperTokenizer.from_pretrained(MODEL_NAME, language=\"german\", task=\"transcribe\")\n",
    "processor = WhisperProcessor.from_pretrained(MODEL_NAME, language=\"german\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text_asr': 'grüß Gott könnten Sie mir bitte sagen welche Zahlungen in letzter Zeit von meinem Konto getätigt wurden ich sehe hier nämlich eine Transaktion die ich nicht selbst getätigt habe', 'audio': {'path': None, 'array': array([ 4.68769576e-06,  2.67913128e-06, -4.74229273e-06, ...,\n",
      "        2.93334277e-04,  2.75355560e-04,  1.11240457e-04]), 'sampling_rate': 16000}}\n"
     ]
    }
   ],
   "source": [
    "print(ds[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    # load and resample audio data from 48 to 16kHz\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array\n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "    # encode target text to label ids\n",
    "    batch[\"labels\"] = tokenizer(batch[\"text_asr\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4): 100%|██████████| 488/488 [00:09<00:00, 49.64 examples/s] \n",
      "Map (num_proc=4): 100%|██████████| 62/62 [00:01<00:00, 51.91 examples/s]\n",
      "Map (num_proc=4): 100%|██████████| 61/61 [00:01<00:00, 51.99 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds = ds.map(prepare_dataset, remove_columns=ds.column_names[\"train\"], num_proc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(MODEL_NAME).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generation_config.language = \"german\"\n",
    "model.generation_config.task = \"transcribe\"\n",
    "model.generation_config.forced_decoder_ids = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "    decoder_start_token_id: int\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
    "    processor=processor,\n",
    "    decoder_start_token_id=model.config.decoder_start_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./whisper-large-ger-lr1.5\",  \n",
    "    gradient_accumulation_steps=2,  # increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=4,\n",
    "    max_steps=61,\n",
    "    gradient_checkpointing=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    save_steps=8,\n",
    "    eval_steps=8,\n",
    "    logging_steps=8,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.save_pretrained(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/61 [00:00<?, ?it/s]Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 16.64 GB, other allocations: 406.12 MB, max allowed: 18.13 GB). Tried to allocate 1.34 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pr3_venv/lib/python3.10/site-packages/transformers/trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1937\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1939\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pr3_venv/lib/python3.10/site-packages/transformers/trainer.py:2279\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2279\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2282\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2283\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2284\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2285\u001b[0m ):\n\u001b[1;32m   2286\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2287\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pr3_venv/lib/python3.10/site-packages/transformers/trainer.py:3349\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3347\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   3348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3349\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pr3_venv/lib/python3.10/site-packages/accelerate/accelerator.py:2159\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2157\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2159\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pr3_venv/lib/python3.10/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pr3_venv/lib/python3.10/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pr3_venv/lib/python3.10/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pr3_venv/lib/python3.10/site-packages/torch/autograd/function.py:306\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    304\u001b[0m     )\n\u001b[1;32m    305\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pr3_venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:313\u001b[0m, in \u001b[0;36mCheckpointFunction.backward\u001b[0;34m(ctx, *args)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(outputs_with_grad) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    310\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone of output has requires_grad=True,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    311\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m this checkpoint() is not necessary\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    312\u001b[0m     )\n\u001b[0;32m--> 313\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs_with_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_with_grad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    315\u001b[0m     inp\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inp, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inp \u001b[38;5;129;01min\u001b[39;00m detached_inputs\n\u001b[1;32m    317\u001b[0m )\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m+\u001b[39m grads\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pr3_venv/lib/python3.10/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pr3_venv/lib/python3.10/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 16.64 GB, other allocations: 406.12 MB, max allowed: 18.13 GB). Tried to allocate 1.34 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>grad_norm</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_wer</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>train_runtime</th>\n",
       "      <th>train_samples_per_second</th>\n",
       "      <th>train_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9449</td>\n",
       "      <td>9.307695</td>\n",
       "      <td>9.298246e-06</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>8</td>\n",
       "      <td>0.693949</td>\n",
       "      <td>21.669477</td>\n",
       "      <td>59.3241</td>\n",
       "      <td>1.045</td>\n",
       "      <td>0.135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5749</td>\n",
       "      <td>7.661010</td>\n",
       "      <td>7.894737e-06</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>16</td>\n",
       "      <td>0.480464</td>\n",
       "      <td>18.549747</td>\n",
       "      <td>67.3638</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5448</td>\n",
       "      <td>12.722649</td>\n",
       "      <td>6.491228e-06</td>\n",
       "      <td>0.393443</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.393443</td>\n",
       "      <td>24</td>\n",
       "      <td>0.468571</td>\n",
       "      <td>20.320405</td>\n",
       "      <td>70.6336</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5174</td>\n",
       "      <td>9.939457</td>\n",
       "      <td>5.087719e-06</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>32</td>\n",
       "      <td>0.444150</td>\n",
       "      <td>18.212479</td>\n",
       "      <td>69.6845</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.3649</td>\n",
       "      <td>8.216652</td>\n",
       "      <td>3.684211e-06</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>40</td>\n",
       "      <td>0.433102</td>\n",
       "      <td>18.128162</td>\n",
       "      <td>68.6008</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.4473</td>\n",
       "      <td>13.482677</td>\n",
       "      <td>2.280702e-06</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>48</td>\n",
       "      <td>0.422880</td>\n",
       "      <td>17.875211</td>\n",
       "      <td>62.8384</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.3728</td>\n",
       "      <td>8.220904</td>\n",
       "      <td>8.771930e-07</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>56</td>\n",
       "      <td>0.418521</td>\n",
       "      <td>17.706577</td>\n",
       "      <td>65.0273</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>916.0768</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.067</td>\n",
       "      <td>1.408297e+17</td>\n",
       "      <td>0.525885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      loss  grad_norm  learning_rate     epoch  step  eval_loss   eval_wer  \\\n",
       "0   0.9449   9.307695   9.298246e-06  0.131148     8        NaN        NaN   \n",
       "1      NaN        NaN            NaN  0.131148     8   0.693949  21.669477   \n",
       "2   0.5749   7.661010   7.894737e-06  0.262295    16        NaN        NaN   \n",
       "3      NaN        NaN            NaN  0.262295    16   0.480464  18.549747   \n",
       "4   0.5448  12.722649   6.491228e-06  0.393443    24        NaN        NaN   \n",
       "5      NaN        NaN            NaN  0.393443    24   0.468571  20.320405   \n",
       "6   0.5174   9.939457   5.087719e-06  0.524590    32        NaN        NaN   \n",
       "7      NaN        NaN            NaN  0.524590    32   0.444150  18.212479   \n",
       "8   0.3649   8.216652   3.684211e-06  0.655738    40        NaN        NaN   \n",
       "9      NaN        NaN            NaN  0.655738    40   0.433102  18.128162   \n",
       "10  0.4473  13.482677   2.280702e-06  0.786885    48        NaN        NaN   \n",
       "11     NaN        NaN            NaN  0.786885    48   0.422880  17.875211   \n",
       "12  0.3728   8.220904   8.771930e-07  0.918033    56        NaN        NaN   \n",
       "13     NaN        NaN            NaN  0.918033    56   0.418521  17.706577   \n",
       "14     NaN        NaN            NaN  1.000000    61        NaN        NaN   \n",
       "\n",
       "    eval_runtime  eval_samples_per_second  eval_steps_per_second  \\\n",
       "0            NaN                      NaN                    NaN   \n",
       "1        59.3241                    1.045                  0.135   \n",
       "2            NaN                      NaN                    NaN   \n",
       "3        67.3638                    0.920                  0.119   \n",
       "4            NaN                      NaN                    NaN   \n",
       "5        70.6336                    0.878                  0.113   \n",
       "6            NaN                      NaN                    NaN   \n",
       "7        69.6845                    0.890                  0.115   \n",
       "8            NaN                      NaN                    NaN   \n",
       "9        68.6008                    0.904                  0.117   \n",
       "10           NaN                      NaN                    NaN   \n",
       "11       62.8384                    0.987                  0.127   \n",
       "12           NaN                      NaN                    NaN   \n",
       "13       65.0273                    0.953                  0.123   \n",
       "14           NaN                      NaN                    NaN   \n",
       "\n",
       "    train_runtime  train_samples_per_second  train_steps_per_second  \\\n",
       "0             NaN                       NaN                     NaN   \n",
       "1             NaN                       NaN                     NaN   \n",
       "2             NaN                       NaN                     NaN   \n",
       "3             NaN                       NaN                     NaN   \n",
       "4             NaN                       NaN                     NaN   \n",
       "5             NaN                       NaN                     NaN   \n",
       "6             NaN                       NaN                     NaN   \n",
       "7             NaN                       NaN                     NaN   \n",
       "8             NaN                       NaN                     NaN   \n",
       "9             NaN                       NaN                     NaN   \n",
       "10            NaN                       NaN                     NaN   \n",
       "11            NaN                       NaN                     NaN   \n",
       "12            NaN                       NaN                     NaN   \n",
       "13            NaN                       NaN                     NaN   \n",
       "14       916.0768                     0.533                   0.067   \n",
       "\n",
       "      total_flos  train_loss  \n",
       "0            NaN         NaN  \n",
       "1            NaN         NaN  \n",
       "2            NaN         NaN  \n",
       "3            NaN         NaN  \n",
       "4            NaN         NaN  \n",
       "5            NaN         NaN  \n",
       "6            NaN         NaN  \n",
       "7            NaN         NaN  \n",
       "8            NaN         NaN  \n",
       "9            NaN         NaN  \n",
       "10           NaN         NaN  \n",
       "11           NaN         NaN  \n",
       "12           NaN         NaN  \n",
       "13           NaN         NaN  \n",
       "14  1.408297e+17    0.525885  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "trainer_history = pd.DataFrame(trainer.state.log_history)\n",
    "trainer_history.groupby('step').first().reset_index()\n",
    "trainer_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot WER over training steps\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot WER\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(trainer_history['step'], trainer_history['eval_wer'], marker='o', label='WER')\n",
    "plt.title(\"WER over Training Steps\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"WER Evaluation\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading model or processor: Can't load tokenizer for '/Users/shabiras/Developer/Learn/AI/NLP/INDONESIA AI/Project_3/whisper-small-ger-lr3.5/checkpoint-61'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/Users/shabiras/Developer/Learn/AI/NLP/INDONESIA AI/Project_3/whisper-small-ger-lr3.5/checkpoint-61' is the correct path to a directory containing all relevant files for a WhisperTokenizer tokenizer.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
    "\n",
    "# Define the path to the model checkpoint\n",
    "model_path = \"/Users/shabiras/Developer/Learn/AI/NLP/INDONESIA AI/Project_3/whisper-small-ger-lr3.5/checkpoint-61\"\n",
    "\n",
    "# Load the best fine-tuned model\n",
    "try:\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(model_path)\n",
    "    processor = WhisperProcessor.from_pretrained(model_path)\n",
    "    print(\"Model and processor loaded successfully.\")\n",
    "except OSError as e:\n",
    "    print(f\"Error loading model or processor: {e}\")\n",
    "\n",
    "# Inference function\n",
    "def transcribe(audio):\n",
    "    input_features = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"], return_tensors=\"pt\").input_features\n",
    "    predicted_ids = model.generate(input_features)\n",
    "    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
    "    return transcription[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "Reference: guten Tag ich möchte einen Konto mit meinem partner eröffnen wie kann ich bitte ein Gemeinschaftskonto einrichten kann ich das in der abmachen\n",
      "Prediction: guten Tag ich möchte einen Konto mit meinem Partner eröffnen wie kann ich bitte ein Gemeinschaftskonto einrichten kann ich das in der Art machen\n",
      "Inference time: 1.0522 seconds\n",
      "\n",
      "Sample 2:\n",
      "Reference: hallo guten Tag ich rufe an weil meine Kreditkarte nicht mehr funktioniert ich habe vorhin versucht im Laden zu bezahlen ich habe die Karte eingesteckt ich habe versucht kontaktlos zu bezahlen und ich kann damit einfach nicht bezahlen funktioniert nicht die Karte scheint kaputt zu sein\n",
      "Prediction: Hallo guten Tag ich rufe an weil meine Kreditkarte nicht mehr funktioniert ich habe vorhin versucht im Laden zu bezahlen ich habe die Karte eingesteckt ich habe es versucht Kontaktlos zu bezahlen und ich kann damit einfach nicht bezahlen es funktioniert nicht die Karte schreien kaputt zu sein\n",
      "Inference time: 1.6257 seconds\n",
      "\n",
      "Sample 3:\n",
      "Reference: Entschuldigung wie kann ich dann am Geldautomaten Geld abheben\n",
      "Prediction: Entschuldigung wie kann ich dann am Geldautomaten Geld abheben\n",
      "Inference time: 0.7579 seconds\n",
      "\n",
      "WER for 3 samples: 0.10256410256410256\n"
     ]
    }
   ],
   "source": [
    "# Run inference on three samples\n",
    "for i in range(3):\n",
    "    sample = ds2[\"test\"][i]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    transcription = transcribe(sample[\"audio\"])\n",
    "    end_time = time.time()\n",
    "    \n",
    "    inference_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"Reference: {sample['text_asr']}\")\n",
    "    print(f\"Prediction: {transcription}\")\n",
    "    print(f\"Inference time: {inference_time:.4f} seconds\")\n",
    "    print()\n",
    "\n",
    "# Calculate overall WER for these three samples\n",
    "wer = metric.compute(predictions=[transcribe(ds[\"test\"][i][\"audio\"]) for i in range(3)],\n",
    "                     references=[ds2[\"test\"][i][\"text_asr\"] for i in range(3)])\n",
    "print(f\"WER for 3 samples: {wer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sounddevice in /opt/anaconda3/envs/pr3_venv/lib/python3.10/site-packages (0.4.7)\n",
      "Requirement already satisfied: CFFI>=1.0 in /opt/anaconda3/envs/pr3_venv/lib/python3.10/site-packages (from sounddevice) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/envs/pr3_venv/lib/python3.10/site-packages (from CFFI>=1.0->sounddevice) (2.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install sounddevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording finished.\n",
      "Transcription: verbangen Systeme von einem vorab die ganze\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "\n",
    "# Function to record audio from the microphone\n",
    "def record_audio(duration, sample_rate=16000):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype='float32')\n",
    "    sd.wait()  # Wait until the recording is finished\n",
    "    print(\"Recording finished.\")\n",
    "    audio = np.squeeze(audio)  # Remove single-dimensional entries\n",
    "    return {\"array\": audio, \"sampling_rate\": sample_rate}\n",
    "\n",
    "# Record audio from the microphone\n",
    "duration = 5  # Record for 5 seconds\n",
    "audio = record_audio(duration)\n",
    "\n",
    "# Transcribe the recorded audio\n",
    "transcription = transcribe(audio)\n",
    "print(\"Transcription:\", transcription)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pr3_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
